# Distribuciones de probabilidad conjunta

En el caso univariado se tenia a una va $X$ definida en los reales $\mathbb R$, a esta va se le asignaba una función de distribución $F(x)$ y una función de densidad $f(x)$. Ambas distribuciones tienen su correspondencia en lo discreto y lo continuo:

Caso discreto:

$$\sum_{Rx} P(X=x)=1$$
$$F(t)=P(X\leq t)=\sum_{x\leq t} P(X=x)$$

Caso continuo:

$$\int_{Rx}f(x)dx=1$$

$$F(t)=P(X\leq t)=\int_{-\infty}^{t}f(x)dx$$

Recordar que las funciones de probabilidad estudiadas en estadística I son funciones útiles cuando es posible vincular su comportamiento a los datos. Estas funciones son llamadas distribuciones/funciones paramétricas. Algunos ejemplos:

  * $X \sim Bernoulli(P)$
  * $X \sim Binomial(n,P)$
  * $X \sim exp(\lambda)$
  * $X \sim N(\mu,\sigma)$

La idea de este capitulo es ver las propiedades en el caso bivariante ($X_1,X_2$) y generalizar para el caso multivariante ($X_1, X_2, X_3, \ldots, X_n$).

## Variables aleatorias bivariantes

Son un *par* de variables aleatorias con una *distribución conjunta*, son tipicamente representadas con mayúscula $(X, Y)$ o $(X_1,X_2)$, las realizaciones de estas variables aleatorias se representan como $(x,y)$ o $(x_1,x_2)$.

> Definición 1: 

Un par de variables aleatorias bivariadas es un par numérico de resultados; una función definida en $\mathbb R^2$

Ejemplos: 

  * Considerar el par (edad, estatura cm):
    + $(23,170)$
    + $(20,172)$
    + $(20,154)$
    + $(26,159)$
    + $(19,175)$
  * Considerar el par: (ingreso, años experiencia)
  
Imaginar lanzar 2 monedas simultáneamente, $\Omega=\{CC,CS,SC,SS\}$, si definimos a $Cara=1$ y $Sello=0$, $R_{(X,Y)}=\{(1,1),(1,0),(0,1),(0,0)\}$.

## Función de distribución bivariada

> Definición 2.

La función de distribución conjunta de $(X,Y)$ es 

$$F(x,y)=P(X\leq x,Y\leq y)=P\left[\{X\leq x\} \cap \{Y\leq y\}  \right]$$
Las propiedades de $F$ son similares al caso univariante, 

  * $0\leq F(x,y)\leq 1$.
  * $F(-\infty,-\infty)=0$, $F(\infty,\infty)=1$

Funciones de densidad/probabilidad bivariadas

  * Discreto: $p(x_1,x_2)=P(X_1=x_1,X_2=x_2)=\pi(x_1,x_2)$

$$0 \leq  \pi(x_1,x_2) \leq 1$$

$$\sum_{Rx_1}\sum_{Rx_2} \pi(x_1,x_2)=1$$

  * Continuo: $f(x_1,x_2)$

$$\int_{Rx_1}\int_{Rx_2} f(x_1,x_2)dx_2 dx_1=1$$

Ejercicio 1: Sea la siguiente función de densidad:

$$f(x_1,x_2)=\frac{1}{500}; \quad  0<x_1<0.25 \quad 0 < x_2<2000$$
  + Verificar si es una función de densidad
  + Encontrar la función de distribución ($F$)

$$F(x_1,x_2)=\frac{x_1 x_2}{500}$$  
  
  + Calcular la probabilidad de:

$$P(x_1>0.1,x_2<1000)=0.3$$
$$P(x_1=0.1,x_2<500)=0$$
  
> Ejercicio.

Sea la función de distribución:

$$F(x,y)=(1-e^{-x})(1-e^{-y});\hspace{2cm} x,y\geq0 $$
Se pide: 

  * Verificar si es una función de distribución
  * $P(X<5,Y<10)$
  * $P(X>100,Y<50)$

Solución:

  * Verificar si es una función de distribución
  
$$F(X=0,Y=0)=F(0,0)=(1-e^{-0})(1-e^{-0})=0$$

$$\lim_{t_1,t_2 \rightarrow \infty} F(t_1,t_2)=(1-e^{-\infty})(1-e^{-\infty})=1$$  
  
  * $P(X<5,Y<10)$

$$F(x,y)=P(X<x,Y<y)=F(5,10)=(1-e^{-5})(1-e^{-10})= 0.993217$$  

```{r}
Fxy<-function(x,y){
  pp<-(1-exp(-x))*(1-exp(-y))
  return(pp)
}
Fxy(5,10)
```

  * $P(X>100,Y<50)=¿?$

La distribución conjunta satisface:
 
$$P(a<X\leq b,c< Y\leq d)=F(b,d)-F(b,c)-F(a,d)+F(a,c)$$
Para $a<b$ y $c<d$

Ejemplo:

* $P(X>100,Y<50)=¿?$

$$P(X>100,Y<50)=F(\infty,50)-F(\infty,0)-F(100,50)+F(100,0)$$
$$=1-0-1+0=0$$

> Definición 3 

$$f(x,y)=\frac{\partial^2}{\partial x \partial y}F(x,y)$$

$$\int_{Rx}\int_{Ry}f(x,y)dydx=1$$

> Ejercicio

Encontrar la función de densidad de:

$$F(x,y)=(1-e^{-x})(1-e^{-y});\hspace{2cm} x,y\geq0$$
Solución

$$f(x,y)=\frac{\partial^2}{\partial x \partial y}\left[(1-e^{-x})(1-e^{-y})\right]=e^{-x}e^{-y}$$

Verificar si efectivamente es una función de densidad

$$\int_0^{\infty}\int_0^{\infty} e^{-x}e^{-y} dx dy=1$$

> Ejercicio

Probar que la siguiente función es una función de densidad

$$f(x,y)=x+y \quad ;0 \leq x \leq 1   \quad 0\leq  y \leq 1$$

$$\int_0^1 \int_0^1 (x+y)  dydx=\int_0^1 \left(x*y/_0^1+\frac{y^2}{2}/_0^1  \right)dx =\int_0^1 x+\frac{1}{2} dx$$
$$=\frac{x^2}{2}/_0^1+\frac{1}{2}=\frac{1}{2}+\frac{1}{2}=1$$


Para el ejercicio:

$$\int_0^{\infty} \int_0^{\infty}e^{-x}e^{-y} dx dy=\int_0^{\infty} e^{-y} \left[-e^{-x}/_0^{\infty} \right] dy =1$$

$$P(a<X\leq b,c< Y\leq d)=\int_a^b \int_c^d f(x,y)dxdy$$

Para el caso discreto podemos definirlo de la siguiente forma:

$$f(x,y)=\pi(x,y)=P(X=x,Y=y)$$
$$\sum_{Rx}\sum_{Ry}\pi(x,y)=1$$
> Ejercicio

Sea la función de probabilidad discreta:

$$\pi(x,y)=\frac{x+y}{30}, \quad x=0,1,2,3; y=0,1,2$$

Verificar que se trata de una función de probabilidad y luego encontrar:

$$P(X\leq 2, Y=1)$$
$$P(X> 2, Y\leq 1)$$
Solución

$$1=\sum_{x=0}^3 \sum_{y=0}^2 \pi(x,y)=\sum_{x=0}^3 \sum_{y=0}^2\frac{x+y}{30}=1$$
$$P(X\leq 2, Y=1)=\pi_{0,1}+\pi_{1,1}+\pi_{2,1}=0.2$$
$$P(X> 2, Y\leq 1)=\pi_{3,0}+\pi_{3,1}=\frac{3}{30}+\frac{4}{30}=\frac{7}{30}$$

Solución en R.

```{r}
#crear la función
pxy<-function(x,y){
  return((x+y)/30)
}
aux<-0
for(x in 0:3){
  for(y in 0:2){
    aux<-aux+pxy(x,y)
  }
}
sum(pxy(0:2,1))
pxy(3,0)+pxy(3,1)
```

> Ejemplo

Sea la función de densidad:

$$f(x,y)=\frac{x}{8}; \quad 0\leq x\leq 2;0\leq y\leq 4 $$
Verificar si es una función de densidad y calcular:

$$P(X>1,Y>2)$$
Obtener la función de distribución ($F$)

Solución

$$\int_0^2 \int_0^4 \frac{x}{8}dy dx=\int_0^2 \frac{x}{8} y/_0^4=\int_0^2\frac{x}{2}dx=\frac{x^2}{4}/_0^2=1$$
$$P(X\geq1,Y\geq2)=P(X>1,Y>2)=\int_1^2 \int_2^4 \frac{x}{8}dy dx=$$
$$=\int_1^2 \frac{x}{8} y/_2^4 dx=\int_1^2 \frac{x}{4} dx= \frac{x^2}{8}/_1^2=\frac{4-1}{8}=\frac{3}{8}$$  
Tarea:

$$F(x,y)=F(t,r)=\int_0^t \int_0^r \frac{x}{8} dy dx$$
  
## Distribución marginal

La distribución conjunta del vector aleatorio $(X,Y)$ describe la distribución del vector aleatorio, sin embargo, es posible a partir de la distribución conjunta, generar las distribuciones para cada componente del vector aleatorio. 

> Definición 4, la distribución marginal de X es:

$$F_X(x)=P(X\leq x)=P(X\leq x, Y\leq \infty)=lim_{y\rightarrow \infty} F(x,y)$$

$$F_Y(y)=P(Y\leq y)=P(X\leq \infty, Y\leq y)=lim_{x\rightarrow \infty} F(x,y)$$
De manera más usual se tiene:

Para el caso discreto:

$$P(X=x)=\pi(x)=\sum_{Ry} \pi(x,y)$$

$$P(Y=y)=\pi(y)=\sum_{Rx} \pi(x,y)$$
Para el caso continuo:

$$f(x)=\int_{Ry} f(x,y)dy$$

$$f(y)=\int_{Rx} f(x,y)dx$$

> Ejercicio

Encontrar las distribuciones marginales de la siguiente función de densidad conjunta:

$$f(x,y)=x^2+\frac{xy}{3}; \quad 0<x\leq 1 \quad  0\leq y \leq2$$

$$f(y)=\int_0^1 x^2+\frac{xy}{3} dx= \frac{x^3}{3}/_0^1+ \frac{yx^2}{6}/_0^1=\frac{1}{3}+\frac{y}{6}$$

$$f(x)=\int_0^2 x^2+\frac{xy}{3} dy=x^2 y/_0^2 + \frac{x y^2}{6}/_0^2=2x^2+\frac{2x}{3}$$

> Ejemplo

Encontrar las distribuciones marginales de la función

$$f(x,y)=\frac{x}{8}; \quad 0\leq x\leq 2 \quad 0\leq y\leq 4$$
Solución:

$$f(x)=\int_0^4 \frac{x}{8} dy= \frac{x}{2}; \quad 0\leq x \leq2$$
$$f(y)=\int_0^2 \frac{x}{8} dx=\frac{x^2}{16}/_0^2=\frac{1}{4}; \quad 0\leq y \leq 4$$

## Independencia

> Definición 6, dos variables aleatorias son independientes si:

Se dice que dos variables aleatorias son independientes si sus funciones de densidad o probabilidad cumplen los siguiente:

$$f(x,y)=f(x)f(y)$$
$$\pi(x,y)=\pi(x)\pi(y)$$
La independencia de dos variables aleatorias implica que el comportamiento de una variable no afecta a la otra. 

> Por ejemplo en el ejercicio con la función:

$$f(x,y)=x^2+\frac{xy}{3}; \quad 0<x\leq 1 \quad  0\leq y \leq2$$

Las variables no son independientes. 

> Para el otro ejemplo:

$$f(x,y)=\frac{x}{8}; \quad 0\leq x\leq 2 \quad 0\leq y\leq 4$$

Efectivamente las variables son independientes. 

> Nota: Cuando definimos la independencia, estamos interesados en entender el nivel de relación que existe en las variables. 

> Ejercicio:

$$f(x,y)=e^{-x}e^{-y}$$

Con $x,y\geq 0$, encontrar las marginales de $f(x)$ y $f(y)$.

Solución:

$$f(x)=\int_0^{\infty}e^{-x}e^{-y} dy=e^{-x}$$

$$f(y)=\int_0^{\infty}e^{-x}e^{-y} dx=e^{-y}$$


Nota: las marginales deben estar en función de su propia variable aleatoria y no contener otras variables, dado que son marginales.

Notar que en este ejercicio:

$$f(x,y)=e^{-x}e^{-y}=f(x)*f(y)$$
Esto no siempre sucede, este caso se da cuando las variables son independientes.

Ejercicio, Sea la función conjunta 

$$f(x,y)=\frac{1}{500}$$

Para $0<X<0.25$ y $0<y<2000$.

  * Verificar que es una función de probabilidad
  * Encontrar la marginal de $x$
  * Encontrar la marginal de $y$

$$\int_0^{0.25}\int_0^{2000}\frac{1}{500}dydx=1$$

$$f(x)=\int_{Ry} f(x,y) dy=\int_0^{2000}\frac{1}{500}dy=4$$
$$f(y)=\int_{Rx} f(x,y) dx=\int_0^{0.25}\frac{1}{500}dx=\frac{1}{2000}$$

> Ejercicio 

Dada la siguiente función de densidad conjunta:

$$f(x,y)=ke^{-2x-3y}; \quad x,y\geq 0$$

  * Encontrar el valor de $k$ para que la función se una función de densidad
  * Encontrar las marginales
  * Verificar si $X$, $Y$ son independientes
  * Calcular las esperanzas y las varianzas a partir de las marginales
  
Solución

$$1=\int_0^\infty \int_0^\infty ke^{-2x-3y}dx dy=k\int_0^\infty e^{-2x} dx \int_0^\infty e^{-3y} dy=k*\frac{1}{2}*\frac{1}{3}$$

Siendo $k=6$, de esta forma la función queda como:

$$f(x,y)=6e^{-2x-3y}; \quad x,y\geq 0$$

Para las marginales:

$$f(x)=\int_0^\infty 6e^{-2x-3y}dy=6 e^{-2x} \left(-\frac{e^{-3y}}{3} \right)/_0^\infty=2e^{-2x}$$

$$f(y)=\int_0^\infty 6e^{-2x-3y}dx=3 e^{-3y}$$

Evidentemente las variables son independientes, ya que:

$$f(x)f(y)=2e^{-2x}3e^{-3y}=6e^{-2x-3y}=f(x,y)$$

> Ejemplo, para la distribución conjunta:

$$f(x,y)=\frac{1}{500}$$

Si $X$ e $Y$ son independientes, se debe cumplir:

$$f(x,y)=f(x)*f(y)=4*\frac{1}{2000}=\frac{1}{500}$$

Ejercicio, verificar si la siguiente función esta bien definida y si las variables son independientes.

$$f(x,y)=\frac{1}{4}(x+y)*xy*e^{-x-y}; \hspace{2cm} x,y>0$$
Solución,

Si esta bien definida, esto significa:

$$\int_0^{\infty}\int_0^{\infty}\frac{1}{4}(x+y)*xy*e^{-x-y}=1$$

$$f(x)=\int_{Ry}f(x,y)dy=\frac{x^2+2x}{4} ( e^{-x})$$
Ejercicio,

Sea la función conjunta:

$$f(x,y)=k (6-x-y) \quad 0<x<2, 2<y<4$$

  * Encontrar el valor de $k$ para que $f$ sea una función de densidad
  * Encontrar las marginales de $x$ e $y$
  * ¿Son independientes?
  
$$\int_{0}^2 \int_2^4 k (6-x-y) dydx=1$$
Así $k=\frac{1}{8}$, de esta forma:

$$f(x,y)=\frac{6-x-y}{8} \quad 0<x<2, 2<y<4$$

$$f(x)=\int_2^4 \frac{6-x-y}{8} dy=\frac{3-x}{4}$$

$$f(y)=\int_0^2 \frac{6-x-y}{8} dx=\frac{5-y}{4}$$
$$f(x)*f(y)=\frac{3-x}{4}*\frac{5-y}{4}\neq \frac{6-x-y}{8}$$
Por lo tanto $x$ e $y$ no son independientes.

## Valores esperados 

En el caso univariado, sea $X$ una variable aleatoria con función de probabilidad $\pi(x)$ para el caso discreto o $f(x)$ para el caso continuo, el operador matemático esperanza se define como:

Para el caso discreto,

$$E[g(X)]=\sum_{Rx}g(x)P(X=x)$$

Para el caso continuo,

$$E[g(X)]=\int_{Rx}g(x)f(x)dx$$

> Definición 6, el valor esperado para la función $g(X,Y)$, se define como:

Para el caso discreto:

$$E[g(X,Y)]=\sum_{Rx}\sum_{Ry}g(x,y)\pi(x,y)$$

Para el caso continuo:

$$E[g(X,Y)]=\int_{Rx}\int_{Ry}g(x,y)f(x.y)dydx$$
Nota, hay valores esperados más usuales que otros,

Por ejemplo, las varianzas para cada variable

$$E[(X-E[X])^2]=V(X)$$
$$E[(Y-E[Y])^2]=V(Y)$$

Otras medidas son $E[X]$, $E[Y]$ que son referencias muy similares a un promedio aritmético. Otra valor esperado bastante usado en los casos bivariados es:

$$E[XY]=\int_{Rx}\int_{Ry} xy f(x,y) dy dx$$
Encontrar la forma de $E[X]$ usando la definición anterior.

$$E[X]=\int_{Rx}\int_{Ry} x f(x,y) dy dx=\int_{Rx}xf(x) dx$$
$$E[X]=\sum_{Rx}\sum_{Ry} x \pi(x,y) =\sum_{Rx}x \pi(x) dx$$

> Ejercicio

Sea la función de densidad:

$$f(x,y)=6 e^{-2x-3y}; \quad x,y \geq 0$$
Encontrar:

  * Las esperanzas: $E[X]$, $E[Y]$  
  * $E[XY]$
  * $E[XY]-E[X]E[Y]$

$$E[XY]=\int_{Rx}\int_{Ry} xy f(x,y) dy dx$$

Solución:

$$E[XY]=\int_0^\infty \int_0^\infty xy 6 e^{-2x-3y}dxdy=6 \int_0^\infty x e^{-2x}dx\int_0^\infty y e^{-3y}dy= \alpha $$

Usando la función gamma.

$$t=2x\quad x=\frac{t}{2} \quad \frac{dx}{dt}=\frac{1}{2}\quad $$

$$\int_0^\infty x e^{-2x}dx=\int_0^\infty\frac{t}{2}e^{-t}\frac{dt}{2}=\frac{1}{4}\int_0^\infty t^{2-1}e^{-t}dt=\frac{\Gamma(2)}{4}=\frac{1!}{4}=\frac{1}{4}$$
$$t=3y\quad y=\frac{t}{3} \quad \frac{dy}{dt}=\frac{1}{3}\quad $$

$$\int_0^\infty y e^{-3x}dx=\int_0^\infty\frac{t}{3}e^{-t}\frac{dt}{3}=\frac{1}{9}\int_0^\infty t^{2-1}e^{-t}dt=\frac{\Gamma(2)}{9}=\frac{1!}{9}=\frac{1}{9}$$
Retomando

$$\alpha=6\frac{1}{4}\frac{1}{9}=\frac{1}{6}=E[XY]$$

$$E[X]=\int_0^\infty x 2e^{-2x}dx=2\int_0^\infty x e^{-2x}dx=\frac{2}{4}=\frac{1}{2}$$

$$E[X^2]=\int_0^\infty x^2 2e^{-2x}dx=2\int_0^\infty x^2 e^{-2x}dx=Tarea$$
$$E[Y]=3*\frac{1}{9}=\frac{1}{3}$$ 
$$E[Y^2]=tarea$$
Notar que 

$$E[X]E[Y]=\frac{1}{2}\frac{1}{3}=\frac{1}{6}=E[XY]$$
$$E[XY]-E[X]E[Y]=\frac{1}{6}-\frac{1}{2}\frac{1}{3}=0$$
Nota:

Cuando dos variables aleatorias son independientes:

$$E[XY]=E[X]E[Y]$$
> Ejercicio, Sea la función conjunta 

$$f(x,y)=\frac{1}{500}, \quad 0<X<0.25 \quad 0<y<2000$$
Encontrar:

  * $E[X]=1/8$, $V[X]=\frac{0.25^2}{12}=\frac{1}{192}$, $E[Y]=1000$, $V[Y]=\frac{2000^2}{12}=\frac{1000000}{3}$
  * $E[XY]$
  

$$E[X]=\int_0^{0.25}\int_0^{2000} x \frac{1}{500}dy dx=\int_0^{0.25}x\int_0^{2000}  \frac{1}{500}dy dx=4\int_0^{0.25}x dx=4*\frac{(x^2)_0^{0.25}}{2}=\frac{1}{8}$$

$$E[XY]=125$$

Nota: Si dos variables aleatorias son independientes:

$$E[XY]=E[X]E[Y]$$
Demostración,

$$E[XY]=\int_{Rx}\int_{Ry} xyf(x,y)dydx=\int_{Rx}\int_{Ry} xyf(x)f(y)dydx=\int_{Rx}x f(x)\left(\int_{Ry} yf(y)dy\right)dx=E[X]*E[Y]$$

Para el caso discreto:

https://docs.google.com/spreadsheets/d/1yJlHbrmKeJ5z4X0YlLayAxOtCWqG6uqQqIgku-aCXEI/edit?usp=sharing 


## Distribuciones condicionales

Recordar de estadística I:

$$P(B/A)=\frac{P(A\cap B)}{P(A)}$$

Estas distribuciones nos ayudan a entender el comportamiento de una variable, cuando fijamos a otra.

> Definición, una distribución condicional se define como:

Caso discreto,

$$\pi_{x/y}(X/Y=y)=\frac{\pi(x,y)}{\pi(y)}$$
$$\pi_{y/x}(Y/X=x)=\frac{\pi(x,y)}{\pi(x)}$$

Caso continuo,

$$f_{X/Y}(x/y)=\frac{f(x,y)}{f(y)}$$
$$f_{Y/X}(y/x)=\frac{f(x,y)}{f(x)}$$
Estas funciones condicionales cumplen todas las propiedades de una función de probabilidad.

Demostrar que:

$$\int_{Rx} f_{X/Y}(x/y) dx=1$$

$$\int_{Rx} f_{X/Y}(x/y) dx=\int_{Rx} \frac{f(x,y)}{f(y)} dx=\frac{1}{f(y)}\int_{Rx} f(x,y)dx=\frac{f(y)}{f(y)}=1$$
Que sucede si $X$ e $Y$ son variables independientes:

$$f_{X/Y}(x/y)=\frac{f(x,y)}{f(y)}=\frac{f(x)f(y)}{f(y)}=f(x)$$
$$f_{Y/X}(y/x)=\frac{f(x,y)}{f(x)}=\frac{f(x)f(y)}{f(x)}=f(y)$$

Ejemplo, caso discreto

(Ver excel compartido)

Ejercicio, 

Sea la densidad conjunta de $X,Y$:

$$f(x,y)=x^2+\frac{xy}{3}, \quad 0<x\leq 1, \quad 0\leq y \leq2$$
Se pide: 

  * Verificar que es una función de probabilidad 
  * Encontrar las marginales 
  * Encontrar las condicionales ($X/Y$, $Y/X$)
  * Encontrar $E[X]$, $E[Y]$, $E[XY]$, $E[X/Y]$, $E[Y/X]$
  * ¿Son independientes?

$$\int_{Rx} \int_{Ry}f(x,y)dydx=\int_0^1 \int_0^2 x^2+\frac{xy}{3} dy dx=1$$

$$f(x)=\int_{Ry}f(x,y)dy=2x^2 +\frac{2x}{3}$$

$$f(y)=\int_{Rx}f(x,y)dx=\frac{1}{3}+\frac{y}{6}$$

$$f_{X/Y}(x/y)=\frac{x^2+\frac{xy}{3}}{\frac{1}{3}+\frac{y}{6}}=\frac{x(3x+y)}{1+\frac{y}{2}}$$

$$f_{Y/X}(y/x)=\frac{x^2+\frac{xy}{3}}{2x^2 +\frac{2x}{3}}=\frac{3x^2+xy}{6x^2+2x}$$

$$E[X]=\int_0^1 x\left( 2x^2 +\frac{2x}{3} \right)dx=\frac{13}{18}$$

$$E[Y]=\int_0^2 y\left( \frac{1}{3}+\frac{y}{6} \right)dy=\frac{10}{9}$$

$$E[XY]=\int_{Rx} \int_{Ry} xy f(x,y)dydx=\int_0^1 \int_0^2 xy \left(x^2+\frac{xy}{3}\right) dy dx=\frac{43}{54}$$

## Esperanza condicional

Se refiere a calcular el valor esperado sobre la función condicional.

$$E[Y/X]=\int_{Ry} y*  f_{Y/X}(y/x)dy$$
$$E[X/Y]=\int_{Rx} x*  f_{X/Y}(x/y)dx$$
Para el ejercicio anterior,

$$E[Y/X]=\int_0^2 y* \left(\frac{3x^2+xy}{6x^2+2x}\right) dy=\frac{9x+4}{9x+3}$$
Calcular:

$$E[Y/X=0.5]=\frac{9*0.5+4}{9*0.5+3}=\frac{8.5}{7.5}=1.13$$

$$E[Y/X=1]=\frac{9*1+4}{9*1+3}=\frac{13}{12}=1.083$$


$$E[Y/X=0.5]=\frac{17}{15}$$
$$E[X/Y]=\frac{9+4y}{12+6y}$$

Nota, si $X$ e $Y$ son independientes,

$$E[X/Y=y]=E[X] \quad;\quad E[Y/X=x]=E[Y] \quad ; \quad E[XY]=E[X]E[Y]$$
Tarea, demostrar lo anterior.

## Medidas de relación entre dos variables

Estas medidas nos ayudan a conocer si dos variables *están relacionadas* y nos permite saber el *tipo de relación* (directa, inversa) y también podemos saber la *intensidad de la relación*. Las medidas son:

La Covarianza $cov(X,Y)$ es una medida absoluta de relación:

$$cov(X,Y)=E\left\{(X-E[X])(Y-E[Y]) \right\}$$

Una alternativa a esta formula (versión corta).

$$cov(X,Y)=E[XY]-E[X]*E[Y]$$
Tarea, demostrar lo anterior.

Nota: La covarianza es una medida absoluta, nos ayuda a conocer el tipo de relación entre las variables, pero no es útil para conocer la intensidad de la relación

Otra medida importantes es la correlación ($corr(X,Y)=\rho_{xy} $) entre $X$ e $Y$, esta es una medida **relativa**, que cumple la propiedad:  $-1 \leq corr(X,Y) \leq 1$, esta se define como:

$$\rho_{xy}=corr(X,Y)=\frac{cov(X,Y)}{\sqrt{V(X)V(Y)}}=\frac{cov(X,Y)}{\sigma_X \sigma_Y}$$

La correlación esta definida en:

$$-1 \leq \rho_{xy} \leq 1$$

  * Si $cov_{xy}$ o $corr_{xy}$ son distintas de 0, podemos afirmar que existe relación (lineal)
  * Si $cov_{xy}>0$ o $corr_{xy}>0$ la relación entre $X$ e $Y$ es **directa**
  * Si $cov_{xy}<0$ o $corr_{xy}<0$ la relación entre $X$ e $Y$ es **inversa**
  * La **intensidad** de la dirección de la relación nos la da $corr_{xy}$, mientras más cercana a $corr_{xy}\rightarrow 1$ la relación directa es más fuerte, $corr_{xy}\rightarrow -1$ la relación inversa es más fuerte 
  * Si $corr_{xy}\rightarrow 0$ podemos decir que las variables no están relacionadas ("cuasi-independencia") la correlación mide principalmente *relaciones lineales*.
  
Nota: 
  * Si las variables $X,Y$ son independientes, entonces, siempre se cumple que la covarianza y la correlación es igual a 0.
  * Si la covarianza o la correlación es igual a 0, eso no implica independencia. Alerta de baja relación o una relación distinta a la lineal.
  
Ejercicio:

Sea la función de densidad:
$$f(x,y)=x+y; \quad 0<x<1 \quad 0<y<1$$
Encontrar el coeficiente de correlación

$$E[XY]=\int_0^1 \int_0^1 xy (x+y)dxdy= \int_0^1 \int_0^1 x^2y +xy^2dxdy=$$
$$=\int_0^1 \frac{x^3 y}{3}/_0^1+\frac{x^2 y^2}{2}/_0^1 dy=\int_0^1 \frac{y}{3}+\frac{y^2}{2}dy=\frac{y^2}{6}/_0^1+\frac{y^3}{6}/_0^1=\frac{1}{3}$$

$$f(x)=\int_0^1 (x+y) dy=x*y/_0^1+\frac{y^2}{2}/_0^1=x+\frac{1}{2}$$
$$f(y)=y+\frac{1}{2}$$
$$E[X]=\int_0^1 x^2+\frac{x}{2}dx=\frac{1}{3}+\frac{1}{4}=\frac{7}{12}=E[Y]$$

$$cov(X,Y)=E[XY]-E[X]*E[Y]=\frac{1}{3}-\frac{7}{12}\frac{7}{12}=-\frac{1}{144}$$

$$E[X^2]=\int_0^1 x^3+\frac{x^2}{2}dx=\frac{1}{4}+\frac{1}{6}=\frac{5}{12}=E[Y^2]$$

$$V(X)=E[X^2]-E[X]^2=\frac{5}{12}-\left(\frac{7}{12}\right)^2=\frac{11}{144}=V(Y)$$

$$\sigma_X=\sigma_Y=\sqrt{V(X)}=\sqrt{\frac{11}{144}}$$

$$\rho_{xy}=\frac{cov(X,Y)}{\sigma_X \sigma_Y}=\frac{-\frac{1}{144}}{\sqrt{\frac{11}{144}}\sqrt{\frac{11}{144}}}=-\frac{144}{11*144}=-\frac{1}{11}=-0.0909$$


Calcular la Covarianza y la correlación de las variables aleatorias $X,Y$.

$$cov(X,Y)=\frac{43}{54}-\frac{13}{18}*\frac{10}{9}=-\frac{1}{162}$$
> Nota

Demostrar que si $X$ y $Y$ son independientes entonces: 

$$E[XY]=E[X]*E[Y]$$

Demostración,

$$E[XY]=\int_{Rx}\int_{Ry} xy f(x,y) dy dx=\int_{Rx}\int_{Ry} xy f(x)f(y) dy dx$$
$$=\int_{Rx} x f(x)\left( \int_{Ry} y f(y) dy \right) dx=E[Y] \int_{Rx} xf(x)  dx=E[X]E[Y] $$
Como resultado de lo anterior, si $X$ e $Y$ son independientes:

$$cov(X,Y)=E[XY]-E[X]*E[Y]=E[X]E[Y]-E[X]E[Y]=0$$

Si dos variables son independientes la covarianza y la correlación son iguales a cero, el inverso de esta afirmación no necesariamente es cierta.

### Ejemplo

Sea la función de densidad:

$$f(x,y)=\frac{3}{2}(x^2+y^2); \quad 0<x<1;\quad 0<y<1$$
Se pide:

  * Verificar que es una función de densidad
  * Encontrar las marginales
  * Encontrar las distribuciones condicionales
  * Calcular la covarianza y correlación
  * Verificar si son independientes

> Ejercicio

Para 

$$f(x,y)=\frac{x(1+3y^2)}{4} \quad 0<x<2, \quad 0<y<1$$

Calcular 

$$P(1/4<X<1/2 | Y=1/3)$$

Solución

Se debe encontrar $f_{X|Y}(X|Y)=\frac{f(x,y)}{f(y)}$

$$f(y)=\int_0^2 \frac{x(1+3y^2)}{4} dx=\frac{(1+3y^2)}{4} \int_0^2 x dx=\frac{(1+3y^2)}{4} \frac{x^2}{2}/_0^2=$$
$$=\frac{(1+3y^2)}{4}(2)=\frac{(1+3y^2)}{2}$$

$$f_{X|Y}(X|Y)=\frac{\frac{x(1+3y^2)}{4}}{\frac{(1+3y^2)}{2}}=\frac{x}{2}$$
Verificando que sea correcta

$$\int_0^2 \frac{x}{2}dx=\frac{x^2}{4}/_0^2=1$$
$$P(1/4<X<1/2 | Y=1/3)=\int_{1/4}^{1/2} f_{X|Y}(X|Y) dx=\int_{1/4}^{1/2} \frac{x}{2} dx=\frac{x^2}{4}/_{0.25}^{0.5}=$$

$$=\frac{0.5^2}{4}-\frac{0.25^2}{4}=\frac{3}{64}$$

Ejercicio de práctica, 

Sea la función de densidad:

$$f(x,y)=24xy, \quad x>0 \quad y>0 \quad x+y<1$$

  * Verificar si es una función de probabilidad
  * Encontrar la función de distribución $F$
  * Calcular la probabilidad que 
  
$$P(X>0.3 , Y<0.5 )$$

Recordar;

$$F(x,y)=P(X<x,Y<y)$$

Hay que tomar al menos 2 casos:

  * $0<x<1$, $x+y<1$
  * $0<x<1$, $1-x\leq y\leq1$

Para el primer caso:

$$\int_0^y \int_0^x 24xy dxdy=6x^2 y^2$$
Para el segundo caso:

$$\int_0^y \int_0^{1-y} 24xy dxdy=$$
Ejercicio de práctica,

Sea la función de densidad

$$f(x,y)=4 e^{-2(x+y)} \quad x>0 \quad y>0$$
  * Verificar si es una función de probabilidad
  * Suponer que estamos interesados en el comportamiento de la variable: 

$$Z=\frac{X}{Y}$$

encontrar la distribución de $Z$.

Definimos a $z=\frac{x}{y}$ y $w=x+y$. Ahora encontramos las funciones $G$

$$x=\frac{zw}{1+z}; \quad y=\frac{w}{1+z}$$

$$l(w,z)=f(X=G_1(Z,W),Y=G_2(Z,W))*|J(Z,W)|=4 e^{-2(\frac{zw}{1+z}+\frac{w}{1+z})}*\frac{w}{(1+z)^2}$$
$$l(z,w)=\frac{4w e^{-2w}}{(1+z)^2}, \quad w>0, \quad z>0$$
finalmente:

$$f(z)=\int_0^{\infty} \frac{4w e^{-2w}}{(1+z)^2} dw=\frac{1}{(1+z)^2}$$

## Transformaciones

Supongamos que se busca encontrar a partir de la función de densidad $f(X,Y)$ de dos variables X, Y una tercera variable $Z=H_1(X,Y)$. La estrategia para resolver este tipo de problemas es:

  * Definir una cuarta variable $W=H_2(X,Y)$, es elegida por **conveniencia** 
  * Se encuentran $X=G_1(Z,W)$, $Y=G_2(Z,W)$
  * Una vez con estos valores la función conjunta de $Z,W$ es:

$$l(Z,W)=f(X=G_1(Z,W),Y=G_2(Z,W))*|J(Z,W)|$$

Donde $J(Z,W)$ se llama jacobiano de la transformación y es dado por:

$$J(Z,W)=\left|
\begin{array}
& \frac{\partial X }{\partial Z} & \frac{\partial X }{\partial W} \\
\frac{\partial Y }{\partial Z} & \frac{\partial Y }{\partial W}
\end{array}
\right|
$$

> Ejemplo, 

Suponer que tenemos una función de densidad conjunto $f(x,y)$, ahora estamos interesados en encontrar la función de densidad de la variable z, definida como:

$$Z=X+Y=H_1(X,Y)$$
$$Z=XY=H_1(X,Y)$$

> Ejemplo 

Sea la función de densidad conjunta definida como:

$$f(x,y)=4 e^{-2(x+y)} \quad x>0 \quad y>0$$

Encontrar la función de densidad de la variable $Z=X+Y$

$$Z=X+Y=H_1(X,Y); \quad W=Y=H_2(X,Y)$$
$$X=Z-W=G_1(Z,W) \quad Y=W=G_2(Z,W)$$

$$J(Z,W)=\left|
\begin{array}
& \frac{\partial X }{\partial Z} & \frac{\partial X }{\partial W} \\
\frac{\partial Y }{\partial Z} & \frac{\partial Y }{\partial W}
\end{array}
\right|=\left|
\begin{array}
& 1 & -1 \\
0 & 1 
\end{array}
\right|=1
$$

$$l(z,w)=4 e^{-2(z-w+w)}|1|=4e^{-2z}; z>0,w>0$$

$$l(z)=\int_0^\infty 4e^{-2z}dw=4e^{-2z} w/_0^\infty=$$

Se debe volver a plantear una nueva forma de $W$

## Distrubuciones conjuntas de más de 2 variables aleatorias

Estamos introduciendo ahora $n$ variables aleatorias, que se puede denotar por vector 

$$\left[X_1,X_2,\ldots,X_n \right]$$

Se puede definir su función de densidad conjunta:

$$f(X_1,X_2,\ldots,X_n)$$
Evidentemente esta función cumple con:

$$\int_{Rx_1}\int_{Rx_2}\ldots \int_{Rx_n}f(X_1,X_2,\ldots,X_n)dx_n\ldots dx_2dx_1=1$$

$$f(X_1,X_2,\ldots,X_n)\geq 0$$

Las marginales de cada variables se obtienen integrando la función de densidad sobre todas las variables aleatorias excepto la variable de interés.

$$f(x_i)=\int \ldots\int_{Rx_{j\neq i}} f(X_1,X_2,\ldots,X_n)dx\ldots dx_{j \neq i}$$
Notar también que si las $n$ variables aleatorias son independientes entre ellas:

$$f(X_1,X_2,\ldots,X_n)=f(X_1)*f(X_2)*\ldots f(X_n)$$

Si estamos interesados en encontrar la covarianza entre dos variables aleatorias de estas $n$ va.

$$cov(X_i,X_j)=E[X_i X_j]-E[X_i]E[X_j] \quad i \neq j$$
$$f(x_i,x_j)=\int \ldots\int_{k\neq i,j} f(x_1,x_2,\ldots,x_n)dx_{k\neq i,j}$$
