<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Estimaciones de una y dos muestrales | Estadística II</title>
  <meta name="description" content="Este libro esta destinado a la materia de Estadística II de la carrera de Estadística de la Universidad Mayor de San Andres." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Estimaciones de una y dos muestrales | Estadística II" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Este libro esta destinado a la materia de Estadística II de la carrera de Estadística de la Universidad Mayor de San Andres." />
  <meta name="github-repo" content="alvarolimber/EST-145" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Estimaciones de una y dos muestrales | Estadística II" />
  
  <meta name="twitter:description" content="Este libro esta destinado a la materia de Estadística II de la carrera de Estadística de la Universidad Mayor de San Andres." />
  

<meta name="author" content="Alvaro Chirino Gutierrez" />


<meta name="date" content="2021-09-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="tema-2-distribuciones-muestrales.html"/>
<link rel="next" href="prueba-de-hipótesis.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#audiencia"><i class="fa fa-check"></i>Audiencia</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#estructura-del-libro"><i class="fa fa-check"></i>Estructura del libro</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-y-acuerdos"><i class="fa fa-check"></i>Software y acuerdos</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#bases-de-datos"><i class="fa fa-check"></i>Bases de datos</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#agradecimiento"><i class="fa fa-check"></i>Agradecimiento</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="tema-1-distribuciones-bivariadas-multivariadas.html"><a href="tema-1-distribuciones-bivariadas-multivariadas.html"><i class="fa fa-check"></i><b>1</b> Tema 1: Distribuciones bivariadas (multivariadas)</a>
<ul>
<li class="chapter" data-level="1.1" data-path="tema-1-distribuciones-bivariadas-multivariadas.html"><a href="tema-1-distribuciones-bivariadas-multivariadas.html#variables-aleatorias-bivariantes"><i class="fa fa-check"></i><b>1.1</b> Variables aleatorias bivariantes</a></li>
<li class="chapter" data-level="1.2" data-path="tema-1-distribuciones-bivariadas-multivariadas.html"><a href="tema-1-distribuciones-bivariadas-multivariadas.html#función-de-distribución-bivariada"><i class="fa fa-check"></i><b>1.2</b> Función de distribución bivariada</a></li>
<li class="chapter" data-level="1.3" data-path="tema-1-distribuciones-bivariadas-multivariadas.html"><a href="tema-1-distribuciones-bivariadas-multivariadas.html#función-masa-de-probabilidad-función-de-densidad"><i class="fa fa-check"></i><b>1.3</b> Función masa de probabilidad (función de densidad)</a></li>
<li class="chapter" data-level="1.4" data-path="tema-1-distribuciones-bivariadas-multivariadas.html"><a href="tema-1-distribuciones-bivariadas-multivariadas.html#distribución-marginal"><i class="fa fa-check"></i><b>1.4</b> Distribución marginal</a></li>
<li class="chapter" data-level="1.5" data-path="tema-1-distribuciones-bivariadas-multivariadas.html"><a href="tema-1-distribuciones-bivariadas-multivariadas.html#independencia"><i class="fa fa-check"></i><b>1.5</b> Independencia</a></li>
<li class="chapter" data-level="1.6" data-path="tema-1-distribuciones-bivariadas-multivariadas.html"><a href="tema-1-distribuciones-bivariadas-multivariadas.html#valores-esperados"><i class="fa fa-check"></i><b>1.6</b> Valores esperados</a></li>
<li class="chapter" data-level="1.7" data-path="tema-1-distribuciones-bivariadas-multivariadas.html"><a href="tema-1-distribuciones-bivariadas-multivariadas.html#distribuciones-condicionales"><i class="fa fa-check"></i><b>1.7</b> Distribuciones condicionales</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="tema-1-distribuciones-bivariadas-multivariadas.html"><a href="tema-1-distribuciones-bivariadas-multivariadas.html#esperanza-condicional"><i class="fa fa-check"></i><b>1.7.1</b> Esperanza condicional</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="tema-1-distribuciones-bivariadas-multivariadas.html"><a href="tema-1-distribuciones-bivariadas-multivariadas.html#medidas-de-relación-entre-dos-variables"><i class="fa fa-check"></i><b>1.8</b> Medidas de relación entre dos variables</a></li>
<li class="chapter" data-level="1.9" data-path="tema-1-distribuciones-bivariadas-multivariadas.html"><a href="tema-1-distribuciones-bivariadas-multivariadas.html#transformaciones"><i class="fa fa-check"></i><b>1.9</b> Transformaciones</a></li>
<li class="chapter" data-level="1.10" data-path="tema-1-distribuciones-bivariadas-multivariadas.html"><a href="tema-1-distribuciones-bivariadas-multivariadas.html#distrubuciones-conjuntas-de-más-de-2-variables-aleatorias"><i class="fa fa-check"></i><b>1.10</b> Distrubuciones conjuntas de más de 2 variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tema-2-distribuciones-muestrales.html"><a href="tema-2-distribuciones-muestrales.html"><i class="fa fa-check"></i><b>2</b> Tema 2: Distribuciones muestrales</a>
<ul>
<li class="chapter" data-level="2.1" data-path="tema-2-distribuciones-muestrales.html"><a href="tema-2-distribuciones-muestrales.html#muestras-y-población"><i class="fa fa-check"></i><b>2.1</b> Muestras y población</a></li>
<li class="chapter" data-level="2.2" data-path="tema-2-distribuciones-muestrales.html"><a href="tema-2-distribuciones-muestrales.html#parámetros-estadísticas-y-estimadores."><i class="fa fa-check"></i><b>2.2</b> Parámetros, estadísticas y estimadores.</a></li>
<li class="chapter" data-level="2.3" data-path="tema-2-distribuciones-muestrales.html"><a href="tema-2-distribuciones-muestrales.html#distribución-muestral"><i class="fa fa-check"></i><b>2.3</b> Distribución muestral</a></li>
<li class="chapter" data-level="2.4" data-path="tema-2-distribuciones-muestrales.html"><a href="tema-2-distribuciones-muestrales.html#distribución-muestral-para-la-media"><i class="fa fa-check"></i><b>2.4</b> Distribución muestral para la media</a></li>
<li class="chapter" data-level="2.5" data-path="tema-2-distribuciones-muestrales.html"><a href="tema-2-distribuciones-muestrales.html#teorema-del-límite-central"><i class="fa fa-check"></i><b>2.5</b> Teorema del límite central</a></li>
<li class="chapter" data-level="2.6" data-path="tema-2-distribuciones-muestrales.html"><a href="tema-2-distribuciones-muestrales.html#distribución-muestral-para-la-diferencia-de-medias"><i class="fa fa-check"></i><b>2.6</b> Distribución muestral para la diferencia de medias</a></li>
<li class="chapter" data-level="2.7" data-path="tema-2-distribuciones-muestrales.html"><a href="tema-2-distribuciones-muestrales.html#distribución-muestral-para-la-proporción"><i class="fa fa-check"></i><b>2.7</b> Distribución muestral para la proporción</a></li>
<li class="chapter" data-level="2.8" data-path="tema-2-distribuciones-muestrales.html"><a href="tema-2-distribuciones-muestrales.html#distribución-muestral-para-la-varianza"><i class="fa fa-check"></i><b>2.8</b> Distribución muestral para la varianza</a></li>
<li class="chapter" data-level="2.9" data-path="tema-2-distribuciones-muestrales.html"><a href="tema-2-distribuciones-muestrales.html#distribución-chi2"><i class="fa fa-check"></i><b>2.9</b> Distribución <span class="math inline">\(\chi^2\)</span></a></li>
<li class="chapter" data-level="2.10" data-path="tema-2-distribuciones-muestrales.html"><a href="tema-2-distribuciones-muestrales.html#distribución-t-student"><i class="fa fa-check"></i><b>2.10</b> Distribución t-student</a></li>
<li class="chapter" data-level="2.11" data-path="tema-2-distribuciones-muestrales.html"><a href="tema-2-distribuciones-muestrales.html#distribución-fisher"><i class="fa fa-check"></i><b>2.11</b> Distribución Fisher</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="tema-2-distribuciones-muestrales.html"><a href="tema-2-distribuciones-muestrales.html#para-las-varianzas-muestrales"><i class="fa fa-check"></i><b>2.11.1</b> Para las varianzas muestrales</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="tema-2-distribuciones-muestrales.html"><a href="tema-2-distribuciones-muestrales.html#ejercicios"><i class="fa fa-check"></i><b>2.12</b> Ejercicios</a>
<ul>
<li class="chapter" data-level="2.12.1" data-path="tema-2-distribuciones-muestrales.html"><a href="tema-2-distribuciones-muestrales.html#ejercicios-del-examen"><i class="fa fa-check"></i><b>2.12.1</b> Ejercicios del examen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html"><i class="fa fa-check"></i><b>3</b> Estimaciones de una y dos muestrales</a>
<ul>
<li class="chapter" data-level="3.1" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#inferencia-estadística"><i class="fa fa-check"></i><b>3.1</b> Inferencia estadística</a></li>
<li class="chapter" data-level="3.2" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#estimadores-puntuales"><i class="fa fa-check"></i><b>3.2</b> Estimadores puntuales</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#estimador-insesgado"><i class="fa fa-check"></i><b>3.2.1</b> Estimador insesgado</a></li>
<li class="chapter" data-level="3.2.2" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#estimador-eficiente"><i class="fa fa-check"></i><b>3.2.2</b> Estimador eficiente</a></li>
<li class="chapter" data-level="3.2.3" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#error-cuadrático-medio-ecm"><i class="fa fa-check"></i><b>3.2.3</b> Error cuadrático medio (ECM)</a></li>
<li class="chapter" data-level="3.2.4" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#cota-de-cramer-rao"><i class="fa fa-check"></i><b>3.2.4</b> Cota de Cramer Rao</a></li>
<li class="chapter" data-level="3.2.5" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#método-de-maxima-verosimilitud"><i class="fa fa-check"></i><b>3.2.5</b> Método de Maxima verosimilitud</a></li>
<li class="chapter" data-level="3.2.6" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#método-de-momentos"><i class="fa fa-check"></i><b>3.2.6</b> Método de momentos</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#estimación-por-intervalos-de-confianza"><i class="fa fa-check"></i><b>3.3</b> Estimación por intervalos de confianza</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#intervalo-de-confianza-para-la-media-asumiendo-varianza-conocida."><i class="fa fa-check"></i><b>3.3.1</b> Intervalo de confianza para la media, asumiendo varianza conocida.</a></li>
<li class="chapter" data-level="3.3.2" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#intervalo-de-confianza-para-la-media-y-la-diferencia-de-medias-con-varianza-desconocida-pero-muestra-mayor-a-30."><i class="fa fa-check"></i><b>3.3.2</b> Intervalo de confianza para la media y la diferencia de medias con varianza desconocida pero muestra mayor a 30.</a></li>
<li class="chapter" data-level="3.3.3" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#intervamuestra-menor-a-30.lo-de-confianza-para-la-media-y-la-diferencia-de-medias-con-varianza-desconocida-pero"><i class="fa fa-check"></i><b>3.3.3</b> Intervamuestra menor a 30.lo de confianza para la media y la diferencia de medias con varianza desconocida pero</a></li>
<li class="chapter" data-level="3.3.4" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#intervalos-de-confianza-para-la-diferencia-de-medias-de-datos-pareados"><i class="fa fa-check"></i><b>3.3.4</b> Intervalos de confianza para la diferencia de medias de datos pareados</a></li>
<li class="chapter" data-level="3.3.5" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#intervalo-de-confianza-para-proporciones"><i class="fa fa-check"></i><b>3.3.5</b> Intervalo de confianza para proporciones</a></li>
<li class="chapter" data-level="3.3.6" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#intervalo-de-confianza-para-diferencia-de-proporciones"><i class="fa fa-check"></i><b>3.3.6</b> Intervalo de confianza para diferencia de proporciones</a></li>
<li class="chapter" data-level="3.3.7" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#intervalo-de-confianza-para-la-varianza"><i class="fa fa-check"></i><b>3.3.7</b> Intervalo de confianza para la varianza</a></li>
<li class="chapter" data-level="3.3.8" data-path="estimaciones-de-una-y-dos-muestrales.html"><a href="estimaciones-de-una-y-dos-muestrales.html#intervalo-de-confianza-para-el-cociente-de-varianzas"><i class="fa fa-check"></i><b>3.3.8</b> Intervalo de confianza para el cociente de varianzas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="prueba-de-hipótesis.html"><a href="prueba-de-hipótesis.html"><i class="fa fa-check"></i><b>4</b> Prueba de Hipótesis</a>
<ul>
<li class="chapter" data-level="4.1" data-path="prueba-de-hipótesis.html"><a href="prueba-de-hipótesis.html#introducción"><i class="fa fa-check"></i><b>4.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="prueba-de-hipótesis.html"><a href="prueba-de-hipótesis.html#hipótesis-estadística"><i class="fa fa-check"></i><b>4.1.1</b> Hipótesis estadística</a></li>
<li class="chapter" data-level="4.1.2" data-path="prueba-de-hipótesis.html"><a href="prueba-de-hipótesis.html#región-de-aceptación-y-región-de-rechazo"><i class="fa fa-check"></i><b>4.1.2</b> Región de aceptación y región de rechazo</a></li>
<li class="chapter" data-level="4.1.3" data-path="prueba-de-hipótesis.html"><a href="prueba-de-hipótesis.html#errores-de-tipo-i-y-errores-de-tipo-ii"><i class="fa fa-check"></i><b>4.1.3</b> Errores de tipo I y errores de tipo II</a></li>
<li class="chapter" data-level="4.1.4" data-path="prueba-de-hipótesis.html"><a href="prueba-de-hipótesis.html#pruebas-bilaterales"><i class="fa fa-check"></i><b>4.1.4</b> Pruebas bilaterales</a></li>
<li class="chapter" data-level="4.1.5" data-path="prueba-de-hipótesis.html"><a href="prueba-de-hipótesis.html#pruebas-unilaterales"><i class="fa fa-check"></i><b>4.1.5</b> Pruebas unilaterales</a></li>
<li class="chapter" data-level="4.1.6" data-path="prueba-de-hipótesis.html"><a href="prueba-de-hipótesis.html#pasos-para-la-prueba-hipótesis-estadística"><i class="fa fa-check"></i><b>4.1.6</b> Pasos para la prueba hipótesis estadística</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="prueba-de-hipótesis.html"><a href="prueba-de-hipótesis.html#prueba-de-hipótesis-sobre-la-media"><i class="fa fa-check"></i><b>4.2</b> Prueba de hipótesis sobre la media</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="prueba-de-hipótesis.html"><a href="prueba-de-hipótesis.html#con-varianza-conocida"><i class="fa fa-check"></i><b>4.2.1</b> Con varianza conocida</a></li>
<li class="chapter" data-level="4.2.2" data-path="prueba-de-hipótesis.html"><a href="prueba-de-hipótesis.html#con-varianza-desconocida"><i class="fa fa-check"></i><b>4.2.2</b> Con varianza desconocida</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="prueba-de-hipótesis.html"><a href="prueba-de-hipótesis.html#prueba-de-hipótesis-sobre-la-diferencia-de-medias"><i class="fa fa-check"></i><b>4.3</b> Prueba de hipótesis sobre la diferencia de medias</a></li>
<li class="chapter" data-level="4.4" data-path="prueba-de-hipótesis.html"><a href="prueba-de-hipótesis.html#prueba-de-hipótesis-sobre-la-proporción"><i class="fa fa-check"></i><b>4.4</b> Prueba de hipótesis sobre la proporción</a></li>
<li class="chapter" data-level="4.5" data-path="prueba-de-hipótesis.html"><a href="prueba-de-hipótesis.html#prueba-de-hipótesis-sobre-la-diferencia-de-proporciones"><i class="fa fa-check"></i><b>4.5</b> Prueba de hipótesis sobre la diferencia de Proporciones</a></li>
<li class="chapter" data-level="4.6" data-path="prueba-de-hipótesis.html"><a href="prueba-de-hipótesis.html#tamaño-de-muestra-y-su-relación-con-el-error-de-tipo-i-y-tipo-ii"><i class="fa fa-check"></i><b>4.6</b> Tamaño de muestra y su relación con el error de tipo I y tipo II</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="estimaciones-de-una-y-dos-muestrales" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Estimaciones de una y dos muestrales</h1>
<div id="inferencia-estadística" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Inferencia estadística</h2>
<p>El proceso por el cual, mediante una muestra estadísticamente
seleccionada se busca describir a la población/universo de la cual esta
proviene. Podemos clasificar a la inferencia estadística en:</p>
<ul>
<li><p><em>Inferencia descriptiva:</em> Tiene el único objetivo de describir a la
población mediante la muestra, tradicionalmente se enfoca en
estimaciones comúnes como; la media, la varianza, total, un
porcentaje, diferencia de medias, diferencia de proporciones.</p>
<ul>
<li>Estimación puntual: <span class="math inline">\(\hat{\theta}\)</span></li>
<li>Estimación por intervalos:
<span class="math inline">\([ \hat{\theta}_{LI},\hat{\theta}_{LS}]\)</span></li>
<li>Pruebas de hipótesis: <span class="math inline">\(\hat{\theta}=k\)</span>, <span class="math inline">\(\hat{\theta}&gt;k\)</span>,
<span class="math inline">\(\hat{\theta}&lt;k\)</span></li>
<li>Tamaño de la muestra (<span class="math inline">\(n\)</span>):
<span class="math inline">\(n=f(U,V(\hat{\theta}),\hat{\theta},\ldots)\)</span></li>
</ul></li>
<li><p><em>Inferencia predictiva:</em> Tiene una idea de estudiar; por un lado, la
evolución de las estimaciones y sus posibles valores futuros (series
de tiempo), por otro lado, le interesa conocer las relaciones (no
causales) entre las variables.</p>
<ul>
<li>Series de tiempo</li>
<li>Modelos lineales</li>
<li>Técnicas multivariantes</li>
<li>etc.</li>
</ul></li>
<li><p><em>Inferencia causal:</em> Tiene el objetivo de medir la relación causal
entre variables. <span class="math inline">\(X \rightarrow Y\)</span></p>
<ul>
<li>Diseños experimentales</li>
<li>Diseños cuasi-experimentales</li>
<li>Modelos estructurales</li>
<li>Etc.</li>
</ul></li>
</ul>
<p>Tarea: Indagar a que se refiere la inferencia bayesiana.</p>
</div>
<div id="estimadores-puntuales" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Estimadores puntuales</h2>
<p>Recordemos que tenemos un universo <span class="math inline">\(U\)</span> de tamaño <span class="math inline">\(N\)</span>.</p>
<p><span class="math display">\[U=\{u_1, u_2,\ldots,u_N\}\]</span> Donde cada unidad del universo tiene
variables (características) asociadas, pensemos en <span class="math inline">\(p\)</span> características.</p>
<p><span class="math display">\[u_i=\{X_{i1},X_{i2}, \ldots , X_{ip}\}\]</span> Un párametro es una función
sobre el universo y sus variables, lo denotamos por <span class="math inline">\(\theta\)</span></p>
<p><span class="math display">\[\theta=f(U,X)\]</span> Un estimador se construye a partir de la definición de
una <em>estadística</em> (<span class="math inline">\(\Theta\)</span>) y tiene el objetivo de aproximar de la
mejor forma a un parámetro. <span class="math inline">\(\hat{\theta}\rightarrow \theta\)</span>.</p>
<p>El estimador <span class="math inline">\(\hat{\theta}\)</span> se construye a partir de una muestra
aleatoria (<span class="math inline">\(s\)</span>) de tamaño <span class="math inline">\(n\)</span> obtenida de <span class="math inline">\(U\)</span>.</p>
<blockquote>
<p>Nota:</p>
</blockquote>
<p>Para un parámetro <span class="math inline">\(\theta\)</span>, pueden existir muchos estimadores
candidatos: <span class="math inline">\(\hat{\theta}_1,\hat{\theta}_2, \hat{\theta}_3,...\)</span>, la
pregunta es ¿Cuál es mejor?. Existen al menos dos criterios:</p>
<div id="estimador-insesgado" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Estimador insesgado</h3>
<p><span class="math display">\[E[\hat{\theta}]=\theta\]</span></p>
</div>
<div id="estimador-eficiente" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Estimador eficiente</h3>
<p>Supongamos que tenemos dos estimadores para <span class="math inline">\(\theta\)</span>, <span class="math inline">\(\hat{\theta}_1\)</span>,
<span class="math inline">\(\hat{\theta}_2\)</span>, el estimador más eficiente entre los dos será quien
tenga el valor más pequeño en su varianza.</p>
<p><span class="math inline">\(min(V(\hat{\theta_1}),V(\hat{\theta_2})) \rightarrow \hat{\theta}\)</span>$</p>
<p>Ejemplo.</p>
<p>Sea el vector <span class="math inline">\(X=\{10,10,20,25,30\}\)</span> de una población con <span class="math inline">\(N=5\)</span>, se
define una muestra de <span class="math inline">\(n=3\)</span> y se busca estimar la media de <span class="math inline">\(X\)</span>: <span class="math inline">\(\mu_x\)</span>.
A partir de los estimadores de la media y la mediana muestral.
Determinar:</p>
<ul>
<li>Son estimadores insesgados</li>
<li>Cuál estimador es más eficiente</li>
</ul>
<p>Suponga un muestreo sin reposición.</p>
<p>Solución.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb71-1" aria-hidden="true" tabindex="-1"></a>x<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="dv">10</span>,<span class="dv">10</span>,<span class="dv">20</span>,<span class="dv">25</span>,<span class="dv">30</span>)</span>
<span id="cb71-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="fu">choose</span>(<span class="dv">5</span>,<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 10</code></pre>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb73-1" aria-hidden="true" tabindex="-1"></a>s<span class="ot">&lt;-</span><span class="fu">combn</span>(x,<span class="dv">3</span>)</span>
<span id="cb73-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="co">#distribución muestral de la media muestral</span></span>
<span id="cb73-3"><a href="estimaciones-de-una-y-dos-muestrales.html#cb73-3" aria-hidden="true" tabindex="-1"></a>dmedia<span class="ot">&lt;-</span><span class="fu">apply</span>(s,<span class="dv">2</span>,mean)</span>
<span id="cb73-4"><a href="estimaciones-de-una-y-dos-muestrales.html#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="co">#distribución muestral de la mediana muestral</span></span>
<span id="cb73-5"><a href="estimaciones-de-una-y-dos-muestrales.html#cb73-5" aria-hidden="true" tabindex="-1"></a>dmediana<span class="ot">&lt;-</span><span class="fu">apply</span>(s,<span class="dv">2</span>,median)</span>
<span id="cb73-6"><a href="estimaciones-de-una-y-dos-muestrales.html#cb73-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Son estimadores insesgados</span></span>
<span id="cb73-7"><a href="estimaciones-de-una-y-dos-muestrales.html#cb73-7" aria-hidden="true" tabindex="-1"></a><span class="co">#media</span></span>
<span id="cb73-8"><a href="estimaciones-de-una-y-dos-muestrales.html#cb73-8" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(dmedia<span class="sc">*</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">10</span>)) <span class="co"># E[]</span></span></code></pre></div>
<pre><code>## [1] 19</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(dmedia)</span></code></pre></div>
<pre><code>## [1] 19</code></pre>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co">#media</span></span>
<span id="cb77-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(dmediana<span class="sc">*</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">10</span>)) <span class="co"># E[]</span></span></code></pre></div>
<pre><code>## [1] 18.5</code></pre>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(dmediana)</span></code></pre></div>
<pre><code>## [1] 18.5</code></pre>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co">#parámetro media poblacional</span></span>
<span id="cb81-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x)</span></code></pre></div>
<pre><code>## [1] 19</code></pre>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cuál estimador es más eficiente</span></span>
<span id="cb83-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb83-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((dmedia<span class="sc">-</span><span class="fu">mean</span>(dmedia))<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span><span class="dv">1</span><span class="sc">/</span><span class="dv">10</span>) <span class="co"># media muestral</span></span></code></pre></div>
<pre><code>## [1] 10.66667</code></pre>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((dmediana<span class="sc">-</span><span class="fu">mean</span>(dmediana))<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span><span class="dv">1</span><span class="sc">/</span><span class="dv">10</span>) <span class="co"># mediana muestral</span></span></code></pre></div>
<pre><code>## [1] 35.25</code></pre>
<p>Para este ejercicio, la media muestral es insesgado y más eficiente que
la mediana muestral.</p>
<blockquote>
<p>Nota</p>
</blockquote>
<p>Los principales problemas de estimación ocurren con frecuencia para
estimar:</p>
<ul>
<li>El promedio o media de una población <span class="math inline">\(\mu\)</span></li>
</ul>
<p><span class="math display">\[\mu_X=\frac{\sum_U X_i}{N}\]</span></p>
<ul>
<li>La varianza poblacional <span class="math inline">\(\sigma^2\)</span></li>
</ul>
<p><span class="math display">\[\sigma^2=\frac{\sum_U (X_i-\mu_X)^2}{N}\]</span></p>
<ul>
<li>La proporción de una característica en la población <span class="math inline">\(P\)</span></li>
</ul>
<p><span class="math display">\[P_A=\frac{\#A}{N}=\frac{\sum_{U} X_i}{N}; \quad \{X_i=1, \quad i \in A, X_i=0,\quad eoc\}\]</span></p>
<ul>
<li>La diferencia de medias de dos poblaciones <span class="math inline">\(\mu_1-\mu_2\)</span></li>
<li>La diferencia de proporciones de dos poblaciones <span class="math inline">\(P_1-P_2\)</span></li>
</ul>
<p>Estimaciones puntuales razonables de estos parámetros son las
siguientes:</p>
<ul>
<li>Para <span class="math inline">\(\mu\)</span>, la estimación es <span class="math inline">\(\hat{\mu_x}=\bar{X}\)</span> la media muestral</li>
</ul>
<p><span class="math display">\[\bar{X}=\frac{\sum_s X_i}{n}\]</span> * Para <span class="math inline">\(\sigma^2\)</span>, la estimación es
<span class="math inline">\(\hat{\sigma}^2=\hat{S^2}\)</span>, la varianza muestral</p>
<p><span class="math display">\[\hat{S}^2=\frac{\sum_s (X_i-\bar{X})^2}{n-1}\]</span> * Para <span class="math inline">\(P\)</span>, la
estimación es <span class="math inline">\(\hat{P}\)</span>, la proporción muestral</p>
<p><span class="math display">\[\hat{P}_A=\frac{\#_sA}{N}=\frac{\sum_{s} X_i}{N}; \quad \{X_i=1, \quad i \in A, X_i=0,\quad eoc\}\]</span>
* Para <span class="math inline">\(\mu_1-\mu_2\)</span>, la estimación es
<span class="math inline">\(\hat{\mu_1}-\hat{\mu}_2=\bar{X}_1-\bar{X}_2\)</span>, la diferencia entre las
medias de las muestras de dos muestras aleatorias independientes. *
Para <span class="math inline">\(P_1-P_2\)</span>, la estimación es <span class="math inline">\(\hat{P_1}-\hat{P}_2\)</span>, la diferencia
entre las proporciones de las muestras de dos muestras aleatorias
independientes.</p>
<p>Ejercicio, Suponga que <span class="math inline">\(X\)</span> es una variable aleatoria con media <span class="math inline">\(\mu\)</span> y
varianza <span class="math inline">\(\sigma^2\)</span>. Sea <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> una muestra aleatoria
de tamaño <span class="math inline">\(n\)</span> de <span class="math inline">\(X\)</span>. DEMOSTRAR que la media de muestra <span class="math inline">\(\bar{X}\)</span> y la
varianza muestral <span class="math inline">\(\hat{S}^2\)</span> son estimadores insesgados de <span class="math inline">\(\mu\)</span> y
<span class="math inline">\(\sigma^2\)</span>, respectivamente.</p>
<p>Como información; <span class="math inline">\(E[X]=\mu\)</span>,</p>
<p><span class="math display">\[V(X)=\sigma^2=E[X^2]-E[X]^2\]</span>.</p>
<p>También recordar que;</p>
<p><span class="math display">\[V(\bar{X})=\frac{\sigma^2}{n}=E[\bar{X}^2]-E[\bar{X}]^2=E[\bar{X}^2]-\mu^2\]</span>
Solución,</p>
<p><span class="math display">\[E[\bar{X}]=E\left[\frac{\sum_s X_i}{n} \right]=\frac{1}{n}\left(\sum_s E[X_i]\right)=\frac{1}{n}\left(\sum_{i=1}^n \mu\right)=\mu \]</span></p>
<p><span class="math display">\[E[\hat{S^2}]=E\left[\frac{\sum_s (X_i-\bar{X})^2}{n-1} \right]=\frac{1}{n-1} E\left[\sum_s (X_i^2-2X_i \bar{X}+\bar{X}^2) \right]=\frac{1}{n-1}E\left[\sum_s X_i^2-2\bar{X} \sum_sX_i +n\bar{X}^2 \right]= \]</span></p>
<p><span class="math display">\[=\frac{1}{n-1}E\left[\sum_s X_i^2-2\bar{X}n\frac{\sum_s X_i}{n}  +n\bar{X}^2 \right]=\frac{1}{n-1}E\left[\sum_s X_i^2-2n\bar{X}^2  +n\bar{X}^2 \right]=\frac{1}{n-1}E\left[\sum_s X_i^2-n\bar{X}^2\right]=\]</span></p>
<p><span class="math display">\[=\frac{1}{n-1}\left(\sum_s E[X_i^2]-nE[\bar{X}^2] \right)= \alpha\]</span>
Notar</p>
<p><span class="math inline">\(\sigma^2=E[X^2]-E[X]^2=E[X^2]-\mu^2\)</span> para un <span class="math inline">\(X_i\)</span>,
<span class="math inline">\(\sigma^2=E[X_i^2]-E[X_i]^2=E[X_i^2]-\mu^2\)</span>, entonces,
<span class="math inline">\(E[X_i]=\sigma^2+\mu^2\)</span>. Por otro lado
<span class="math inline">\(E[\bar{X}^2]=\frac{\sigma^2}{n}+\mu^2\)</span>, Así:</p>
<p><span class="math display">\[\alpha=\frac{1}{n-1}\left[\sum_s (\sigma^2+\mu) -n \left(\frac{\sigma^2}{n}+\mu \right) \right]=\frac{1}{n-1}\left[ n \sigma^2+n\mu -\sigma^2-n\mu  \right]=\frac{\sigma^2(n-1)}{n-1}=\sigma^2\]</span></p>
</div>
<div id="error-cuadrático-medio-ecm" class="section level3" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Error cuadrático medio (ECM)</h3>
<p>Este se define para un estimador como:</p>
<p><span class="math display">\[ECM(\hat{\theta})=E\left[(\hat{\theta}-\theta)^2\right]\]</span></p>
<p>Recordar que
<span class="math inline">\(V(\hat{\theta})=E\left[(\hat{\theta}-E[\hat{\theta}])^2\right]\)</span>.</p>
<p><span class="math display">\[ECM(\hat{\theta})=E\left[\left[(\hat{\theta}-E[\hat{\theta}])-(\theta-E[\hat\theta]) \right]^2\right]=E\left[(\hat{\theta}-E[\hat{\theta}])^2-2(\hat{\theta}-E[\hat{\theta}])(\theta-E[\hat\theta])+ (\theta-E[\hat\theta])^2 \right]=\]</span></p>
<p><span class="math display">\[=E[(\hat{\theta}-E[\hat{\theta}])^2]-2(\theta-E[\hat\theta])E\left[\hat{\theta}-E[\hat{\theta}]\right]+E[(\theta-E[\hat\theta])^2]=V(\hat\theta)=V(\hat{\theta})+E[(\theta-E[\hat\theta])^2]=\]</span></p>
<p><span class="math display">\[=V(\hat{\theta})+sesgo(\hat\theta)^2\]</span></p>
</div>
<div id="cota-de-cramer-rao" class="section level3" number="3.2.4">
<h3><span class="header-section-number">3.2.4</span> Cota de Cramer Rao</h3>
<p>Es posible obtener una cota inferior de la varianza de todos los
estimadores (<span class="math inline">\(\hat{\theta}_1, \hat{\theta}_2,\ldots\)</span>) insesgados de
<span class="math inline">\(\theta\)</span>. Sea <span class="math inline">\(\hat{\theta}\)</span> un estimador insesgado del parámetro
<span class="math inline">\(\theta\)</span>, basado en una muestra aleatorio de <span class="math inline">\(n\)</span> observaciones, y
considérese que <span class="math inline">\(f(x,\theta)\)</span> denota la función de distribución de
probabilidades de una variable aleatoria <span class="math inline">\(X\)</span>. Entonces una cota inferior
en la varianza de <span class="math inline">\(\hat{\theta}\)</span> es:</p>
<p><span class="math display">\[V(\hat{\theta})\geq\frac{1}{nE\left\{ \left[\frac{d}{d\theta }ln f(X,\theta) \right]^2 \right\}}\]</span></p>
<p>Esta desigualdad se denomina <em>cota de Cramer Rao</em>. Si un estimador
insesgado <span class="math inline">\(\hat{\theta}\)</span> satisface la desigualdad, se tratará del
estimador insesgado de varianza mínima de <span class="math inline">\(\theta\)</span>.</p>
<p>Ejemplo, Demostrar que la media muestra <span class="math inline">\(\bar{X}\)</span> es el estimador
insesgado de varianza mínima de la media de una distribución normal con
varianza conocida.</p>
<p>Sea <span class="math inline">\(X\sim N(\mu,\sigma^2)\)</span>, sabemos <span class="math inline">\(E[\bar{X}]=\mu\)</span></p>
<p><span class="math display">\[f(X,\mu)=\frac{1}{\sqrt{2\pi} \sigma}e^{-\frac{1}{2}\left(\frac{X-\mu}{\sigma}\right)^2}\]</span>
<span class="math display">\[ln f(X,\mu)=ln\left( \frac{1}{\sqrt{2\pi} \sigma}e^{-\frac{1}{2}\left(\frac{X-\mu}{\sigma}\right)^2} \right)=-ln\left( \sqrt{2\pi} \sigma \right) -\frac{1}{2}\left(\frac{X-\mu}{\sigma}\right)^2\]</span></p>
<p><span class="math display">\[E\left\{\left[ \frac{d}{d\mu} ln f(X,\mu)\right]^2 \right\}=E\left\{ \left[ \frac{(X-\mu)}{\sigma^2} \right]^2\right\} =E\left[\frac{(X-\mu)^2}{\sigma^4} \right]=\frac{E[(X-\mu)^2]}{\sigma^4}=\]</span>
<span class="math display">\[=\frac{\sigma^2}{\sigma^4}=\frac{1}{\sigma^2}\]</span> Finalmente, para la
cota de Cramer-Rao</p>
<p><span class="math display">\[V(\bar{X})\geq \frac{1}{\frac{n}{\sigma^2}}=\frac{\sigma^2}{n}=V(\bar{X})\]</span></p>
</div>
<div id="método-de-maxima-verosimilitud" class="section level3" number="3.2.5">
<h3><span class="header-section-number">3.2.5</span> Método de Maxima verosimilitud</h3>
<p>Suponga que <span class="math inline">\(X\)</span> es una va, con distribución <span class="math inline">\(f(X,\theta)\)</span>, donde
<span class="math inline">\(\theta\)</span> es un parámetro desconocido. Sean <span class="math inline">\(X_1, X_2,\ldots, X_n\)</span> va.
iid. como <span class="math inline">\(X\)</span>, la muestra de tamaño <span class="math inline">\(n\)</span>. La función de probabilidad de
las <span class="math inline">\(n\)</span> va. se escribe como:</p>
<p><span class="math display">\[f(X_1,X_2, \ldots,X_n,\theta)=f(X_1,\theta)*f(X_2,\theta)*\ldots*f(X_n,\theta)=L(\theta)\]</span>
El estimador de máxima verosimilitud de <span class="math inline">\(\theta\)</span> es el valor que
maximiza la función de probabilidad <span class="math inline">\(L(\theta)\)</span>.</p>
<p>Pasos para obtener el estimador de máxima verosimilitud para un
parámetro <span class="math inline">\(\theta\)</span></p>
<ol style="list-style-type: decimal">
<li>Obtener <span class="math inline">\(L(\theta)\)</span></li>
<li>Calcular <span class="math inline">\(ln [L(\theta)]\)</span></li>
<li>Resolver la ecuación:</li>
</ol>
<p><span class="math display">\[\frac{d}{d\theta} ln [L(\theta)]=0\]</span></p>
<p>En el caso de que tengamos más de un parámetro, los pasos son:</p>
<ol style="list-style-type: decimal">
<li>Obtener
<span class="math inline">\(L(\theta_1,\theta_2,\ldots)=f(X_1,\theta_1,\theta_2,\ldots)*\ldots*f(X_n,\theta_1,\theta_2,\ldots)\)</span></li>
<li>Calcular <span class="math inline">\(ln [L(\theta_1,\theta_2,\ldots)]\)</span></li>
<li>Resolver el sistema de ecuaciones:</li>
</ol>
<p><span class="math display">\[\frac{\partial }{\partial \theta_1} ln [L(\theta_1,\theta_2,\ldots)]=0\]</span>
<span class="math display">\[\frac{\partial }{\partial \theta_2} ln [L(\theta_1,\theta_2,\ldots)]=0\]</span>
<span class="math display">\[\frac{\partial }{\partial \theta_p} ln [L(\theta_1,\theta_2,\ldots)]=0\]</span></p>
<p>Ejemplo,</p>
<p>Sea <span class="math inline">\(X\sim Bernoulli(p)\)</span>, la función de probabilidad es:</p>
<p><span class="math display">\[P(X=x)=\pi(x)=p^x (1-p)^{1-x} \quad ; x=\{0,1\}\]</span></p>
<p>Si <span class="math inline">\(p\)</span> es el parámetro de interés que se busca estimar, ¿qué forma
tendrá el estimador de máxima verosimilitud?</p>
<p>Solución,</p>
<p>Supongamos que se extrae una muestra de tamaño <span class="math inline">\(n\)</span>, así:</p>
<p><span class="math display">\[L(p)=f(X_1,p)*f(X_2,p)*\ldots*f(X_n,p)=p^{x_1} (1-p)^{1-x_1}*p^{x_2} (1-p)^{1-x_2}*\ldots*p^{x_n} (1-p)^{1-x_n}\]</span></p>
<p><span class="math display">\[L(p)=p^{\sum_{i=1}^n x_i}*(1-p)^{n-\sum_{i=1}^n x_i}\]</span></p>
<p><span class="math display">\[ln[ L(p)]= \sum_{i=1}^n x_i ln(p)+\left(n-\sum_{i=1}^n x_i \right) ln(1-p) \]</span></p>
<p><span class="math display">\[\frac{d}{dp}ln[ L(p)]= \frac{\sum_{i=1}^n x_i}{p}-\frac{\left(n-\sum_{i=1}^n x_i\right)}{1-p}=0\]</span></p>
<p><span class="math display">\[ \frac{\sum_{i=1}^n x_i}{p}-\frac{\left(n-\sum_{i=1}^n x_i\right)}{1-p}=0\]</span></p>
<p><span class="math display">\[\hat{p}_{mv}=\frac{\sum_{i=1}^n x_i}{n}\]</span></p>
<p>Ejemplo, Sea <span class="math inline">\(X_1, X_2, \ldots,X_n\)</span>, va iid, tal que
<span class="math inline">\(X_i\sim Poisson(\lambda)\)</span>. Encontrar el estimador de <span class="math inline">\(\lambda\)</span>
empleando el método de máxima verosimilitud.</p>
<p>Solución, recordar que si <span class="math inline">\(X\sim Poisson(\lambda)\)</span></p>
<p><span class="math display">\[\pi(x)=P(X=x)=\frac{e^{-\lambda} \lambda ^x}{x!}; \quad X=\{0,1,2\ldots\}\]</span></p>
<p><span class="math display">\[L(\lambda)=\pi(X_1,\lambda)*\pi(X_2,\lambda)*\ldots*\pi(X_n,\lambda)\]</span></p>
<p><span class="math display">\[L(\lambda)=\frac{e^{-\lambda} \lambda ^{x_1}}{x_1!}*\frac{e^{-\lambda} \lambda ^{x_2}}{x_2!}*\ldots*\frac{e^{-\lambda} \lambda ^{x_n}}{x_n!}\]</span></p>
<p><span class="math display">\[L(\lambda)=\prod_{i=1}^n \frac{e^{-\lambda} \lambda ^{x_i}}{x_i!}=\frac{e^{-n\lambda}\lambda^{\sum_{i=1}^n x_i}}{\prod_{i=1}^n x_i!}\]</span>
<span class="math display">\[ln [L(\lambda)]=-n\lambda+\sum_{i=1}^n x_i ln \lambda - ln \prod_{i=1}^n x_i!\]</span>
<span class="math display">\[\frac{d}{d\lambda}ln [L(\lambda)]=-n+\frac{\sum_{i=1}^n x_i}{\lambda}=0\]</span></p>
<p><span class="math display">\[\hat{\lambda}=\frac{\sum_{i=1}^n x_i}{n}\]</span></p>
<p>Ejemplo, Sea <span class="math inline">\(X_1, X_2, \ldots,X_n\)</span>, va iid, tal que
<span class="math inline">\(X_i\sim exp(\lambda)\)</span>. Encontrar el estimador de <span class="math inline">\(\lambda\)</span> empleando el
método de máxima verosimilitud.</p>
<p>Solución, recordar que si <span class="math inline">\(X\sim exp(\lambda)\)</span> su función de densidad es
dada por:</p>
<p><span class="math display">\[f(x)=\lambda e^{-\lambda x}; \quad x\geq0\]</span></p>
<p><span class="math display">\[L(\lambda)=\prod_{i=1}^n \lambda e^{-\lambda x_i}=\lambda^n e^{-\lambda \sum_{i=1}^n x_i}\]</span>
<span class="math display">\[ln [L(\lambda)]=n ln \lambda-\lambda \sum_{i=1}^n x_i\]</span>
<span class="math display">\[\frac{d}{d\lambda}ln [L(\lambda)]=\frac{n}{\lambda}-\sum_{i=1}^n x_i=0\]</span>
<span class="math display">\[\hat{\lambda}=\frac{1}{\frac{\sum_{i=1}^n x_i}{n}}=\frac{1}{\bar{X}}\]</span></p>
<p>Ejemplo, Sea <span class="math inline">\(X_1, X_2, \ldots,X_n\)</span>, va iid, tal que
<span class="math inline">\(X_i\sim N(\mu,\sigma^2)\)</span> ambos parámetros desconocidos. Encontrar los
estimadores de máxima verosimilitud para <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Solución, recordar si <span class="math inline">\(X\sim N(\mu, \sigma^2)\)</span> su función de densidad es
dada por:</p>
<p><span class="math display">\[f(X)=\frac{1}{\left(2\pi \sigma^2 \right)^{1/2} }e^{-\frac{1}{2}\frac{\left(x-\mu\right)^2}{\sigma^2}}\]</span>
<span class="math display">\[L(\mu,\sigma^2)=\prod_{i=1}^n \frac{1}{\left(2\pi \sigma^2 \right)^{1/2} }e^{-\frac{1}{2}\frac{\left(x_i-\mu\right)^2}{\sigma^2}}=\frac{1}{\left(2\pi \sigma^2 \right)^{n/2} }e^{-\frac{1}{2 \sigma^2}\sum_{i=1}^n \left(x_i-\mu\right)^2}\]</span>
<span class="math display">\[ln[L(\mu,\sigma^2)]=-\frac{n}{2}ln (2\pi \sigma^2)-\frac{1}{2 \sigma^2}\sum_{i=1}^n \left(x_i-\mu\right)^2\]</span>
<span class="math display">\[\frac{\partial}{\partial \mu} ln[L(\mu,\sigma^2)]=\frac{1}{\sigma^2} \sum_{i=1}^n \left(x_i-\mu\right)=0\]</span></p>
<p><span class="math display">\[\frac{\partial}{\partial \sigma^2} ln[L(\mu,\sigma^2)]=-\frac{n}{2 \sigma^2}+\frac{1}{2 \sigma^4}\sum_{i=1}^n \left(x_i-\mu\right)^2=0\]</span>
<span class="math display">\[\sum_{i=1}^n x_i - n\mu=0\]</span>
<span class="math display">\[\hat{\mu}=\frac{\sum_{i=1}^n x_i}{n}=\bar{X}\]</span></p>
<p><span class="math display">\[\hat{\sigma}^2=\frac{\sum_{i=1}^n \left(x_i-\bar{X}\right)^2}{n}\]</span></p>
</div>
<div id="método-de-momentos" class="section level3" number="3.2.6">
<h3><span class="header-section-number">3.2.6</span> Método de momentos</h3>
<p>Este método fue desarrollado por 1894 por Pearson, a diferencia del
método de máxima verosimilitud que fue ampliamente utilizado por Fisher
a partir 1912.</p>
<p>Recordar que para una variable aleatoria, los momentos respecto el
origen son:</p>
<ul>
<li>Primer Momento: <span class="math inline">\(\mu_1=E[X]=\int x f(x) dx\)</span></li>
<li>Segundo Momento: <span class="math inline">\(\mu_2=E[X^2]=\int x^2 f(x) dx\)</span></li>
<li>k-ésimo momento: <span class="math inline">\(\mu_k=E[X^k]\)</span></li>
</ul>
<p>Sea <span class="math inline">\(X_1, X_2, \ldots ,X_n\)</span> una muestra aleatorio de tamaño <span class="math inline">\(n\)</span> de una
va <span class="math inline">\(X\)</span>, definamos los primeros <span class="math inline">\(k\)</span> momentos de la muestra respecto al
origen como:</p>
<ul>
<li>Primer momento:</li>
</ul>
<p><span class="math display">\[m_1=\frac{\sum_{i=1}^n x_i}{n}\]</span></p>
<ul>
<li>Segundo momento:</li>
</ul>
<p><span class="math display">\[m_2=\frac{\sum_{i=1}^n x^2_i}{n}\]</span></p>
<ul>
<li>k-ésimo momento:</li>
</ul>
<p><span class="math display">\[m_k=\frac{\sum_{i=1}^n x^k_i}{n}; \quad k=1,2,\ldots \]</span></p>
<p>Los momentos <span class="math inline">\(\mu_k\)</span> de la población serán funciones de los parámetros
desconocidos <span class="math inline">\(\theta\)</span>. Al igualar estos momentos muestrales con los
poblaciones vamos a poder construir un sistema de ecuaciones de cuantas
incógnitas se defina con la distribución de <span class="math inline">\(X\)</span></p>
<p>Ejemplo, Sea <span class="math inline">\(X_1, X_2, \ldots,X_n\)</span>, va iid, tal que
<span class="math inline">\(X_i\sim exp(\lambda)\)</span>. Encontrar el estimador de <span class="math inline">\(\lambda\)</span> empleando el
método de momentos.</p>
<p>Solución, recordar que si <span class="math inline">\(X\sim exp(\lambda)\)</span> su función de densidad es
dada por:</p>
<p><span class="math display">\[f(x)=\lambda e^{-\lambda x}; \quad x\geq0\]</span> <span class="math display">\[E[X]=m_1\]</span>
<span class="math display">\[E[X]=\int_0^\infty x\lambda e^{-\lambda x}dx=\frac{1}{\lambda}\]</span></p>
<p>Igualando los momentos:</p>
<p><span class="math display">\[\frac{1}{\lambda}=\frac{\sum_s x_i}{n}\]</span></p>
<p><span class="math display">\[\hat{\lambda}= \frac{1}{\frac{\sum_s x_i}{n}}=\frac{1}{\bar{X}}\]</span></p>
<p>Ejercicio, Sea <span class="math inline">\(X\)</span> una va geométrica con parámetro <span class="math inline">\(p\)</span>, encuentre un
estimador de <span class="math inline">\(p\)</span> mediante el método de momentos y el método de máxima
verosimilitud. En base a una muestra aleatoria de tamaño <span class="math inline">\(n\)</span></p>
<p>Recordar que si <span class="math inline">\(X\sim G(p)\)</span>, entonces su distribución de probabilidades
es:</p>
<p><span class="math display">\[\pi(x)=P(X=x)=(1-p)^x p; \quad x=\{0,1,2,\dots\} \]</span></p>
<p>Recordar que <span class="math inline">\(E[X]=\frac{1-p}{p}\)</span>, por el método de momentos:</p>
<p><span class="math display">\[\frac{1-p}{p}=\bar{X}\]</span></p>
<p><span class="math display">\[\hat{p}=\frac{1}{\bar{X}+1}\]</span> Por el método de máxima verosimilitud.</p>
<p><span class="math display">\[L(p)=\prod_{i=1}^n (1-p)^{x_i} p=(1-p)^{\sum_s x_i} p^n\]</span>
<span class="math display">\[ln [L(p)]=\sum_s x_i ln (1-p)+n ln(p)\]</span></p>
<p><span class="math display">\[\frac{d}{dp}ln [L(p)]=-\frac{\sum_s x_i}{1-p}+\frac{n}{p}=0\]</span>
<span class="math display">\[\hat{p}=\frac{1}{\bar{X}+1}\]</span></p>
<p>Tarea, Sea <span class="math inline">\(X\)</span> una normal con parámetro <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma^2\)</span>, encuentre un
estimador de <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma^2\)</span> mediante el método de momentos. En base
a una muestra aleatoria de tamaño <span class="math inline">\(n\)</span></p>
<p><span class="math display">\[\mu=\bar{X}\]</span> <span class="math display">\[E[X^2]=\frac{\sum_s x_i^2}{n}\]</span></p>
<p>Recordar que
<span class="math inline">\(\sigma^2=E[X^2]-E[X]^2=E[X^2]-\mu^2 \approx E[X^2]-\bar{X}^2\)</span>.</p>
</div>
</div>
<div id="estimación-por-intervalos-de-confianza" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Estimación por intervalos de confianza</h2>
<p>Para construir un intervalo de confianza del parámetro desconocido
<span class="math inline">\(\theta\)</span>, se debe encontrar dos estadísticas <span class="math inline">\(L\)</span> y <span class="math inline">\(U\)</span> tales que:</p>
<p><span class="math display">\[P(L\leq\theta\leq U)=1-\alpha\]</span> El intervalo <span class="math inline">\(L\leq\theta\leq U\)</span> se
llama intervalo de confianza del <span class="math inline">\(100*(1-\alpha)\)</span>. A <span class="math inline">\(L\)</span> se lo conoce
como límite inferior y <span class="math inline">\(U\)</span> como límite superior.</p>
<p>La interpretación del intervalo de confianza es que si se coleccionan
muchas muestras aleatorias y se calcula un intervalo de confianza del
<span class="math inline">\(100*(1-\alpha)\)</span> por ciento en <span class="math inline">\(\theta\)</span> de cada muestra, entonces
<span class="math inline">\(100*(1-\alpha)\)</span> por ciento de estos intervalos contendrán el verdadero
valor de <span class="math inline">\(\theta\)</span>.</p>
<div id="intervalo-de-confianza-para-la-media-asumiendo-varianza-conocida." class="section level3" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Intervalo de confianza para la media, asumiendo varianza conocida.</h3>
<p>Sea <span class="math inline">\(X\)</span> una va con media desconocida <span class="math inline">\(\mu\)</span> y varianza conocida
<span class="math inline">\(\sigma^2\)</span>. Suponga que se toma una muestra aleatoria de tamaño <span class="math inline">\(n\)</span>,
<span class="math inline">\(X_1,X_2,\ldots,X_n\)</span>. Puede obtenerse un intervalo de confianza del
<span class="math inline">\(100*(1-\alpha)\)</span> por ciento en <span class="math inline">\(\mu\)</span> considerando la distribución de
muestreo de <span class="math inline">\(X\)</span> de la media muestral <span class="math inline">\(\bar{X}\)</span>. Por el teorema del
límite central sabemos que <span class="math inline">\(\bar{X}\sim N(\mu,\frac{\sigma^2}{n})\)</span> bajo
ciertas condiciones. Así:</p>
<p><span class="math display">\[Z=\frac{\bar{X}-\mu}{\frac{\sigma}{\sqrt{n}}}\]</span> Teniendo a
<span class="math inline">\(Z\sim N(0,1)\)</span>, para armar el intervalo de confianza basta con trabajar
sobre:</p>
<p><span class="math display">\[P(L\leq Z\leq U)=1-\alpha\]</span> Para un intervalo de confianza
<span class="math inline">\(L \leq \theta \le U\)</span> se debe asegurar que la precisión de los lados sea
la misma, <span class="math inline">\(\theta-L=U-\theta\)</span>.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dnorm</span>(x),<span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">3.5</span>,<span class="fl">3.5</span>),<span class="at">xlab=</span><span class="st">&quot;z&quot;</span>)</span>
<span id="cb87-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="dv">0</span>)</span>
<span id="cb87-3"><a href="estimaciones-de-una-y-dos-muestrales.html#cb87-3" aria-hidden="true" tabindex="-1"></a>sx<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">3.5</span>,<span class="fu">seq</span>(<span class="sc">-</span><span class="fl">3.5</span>,<span class="fu">qnorm</span>(<span class="fl">0.025</span>),<span class="fl">0.01</span>),<span class="fu">qnorm</span>(<span class="fl">0.025</span>))</span>
<span id="cb87-4"><a href="estimaciones-de-una-y-dos-muestrales.html#cb87-4" aria-hidden="true" tabindex="-1"></a>sy<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">dnorm</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="fl">3.5</span>,<span class="fu">qnorm</span>(<span class="fl">0.025</span>),<span class="fl">0.01</span>)),<span class="dv">0</span>)</span>
<span id="cb87-5"><a href="estimaciones-de-una-y-dos-muestrales.html#cb87-5" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(sx,sy,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb87-6"><a href="estimaciones-de-una-y-dos-muestrales.html#cb87-6" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">*</span>sx,sy,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.05</span><span class="sc">/</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] -1.959964</code></pre>
<p>Si <span class="math inline">\(\alpha=0.05\)</span></p>
<p><span class="math display">\[P(L\leq Z\leq U)=0.95\]</span></p>
<p><span class="math display">\[P(-Z_{\alpha/2}\leq Z\leq Z_{\alpha/2})=1-\alpha\]</span></p>
<p><span class="math display">\[P\left(-Z_{\alpha/2}\leq \frac{\bar{X}-\mu}{\frac{\sigma}{\sqrt{n}}} \leq Z_{\alpha/2}\right)=1-\alpha\]</span></p>
<p><span class="math display">\[P\left(\bar{X}-Z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\leq\mu \leq \bar{X}+Z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\right)=1-\alpha\]</span>
Así de esta manera tenemos identificados a <span class="math inline">\(L\)</span> y <span class="math inline">\(U\)</span> para <span class="math inline">\(\mu\)</span> con
varianza conocida.</p>
<p><span class="math display">\[L=\bar{X}-Z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\]</span>
<span class="math display">\[U=\bar{X}+Z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\]</span></p>
<p><span class="math inline">\(\alpha\)</span> es conocida como el nivel de significancia y <span class="math inline">\(1-\alpha\)</span> como la
confiabilidad. Los valores más usuales de <span class="math inline">\(\alpha\)</span> son 0.01, 0.05 y 0.1,
para estudios sobre ciencias de la salud el valor recomendado es de 0.01
o menor, para las ciencias sociales y económicas el valor recomendado es
0.05. Para la distribución normal los valores de <span class="math inline">\(Z_{\alpha/2}\)</span> son:</p>
<ul>
<li><span class="math inline">\(\alpha=0.1\)</span>, <span class="math inline">\(Z_{\alpha/2}=Z_{0.05}=1.64\)</span> (90% confiabilidad)</li>
<li><span class="math inline">\(\alpha=0.05\)</span>, <span class="math inline">\(Z_{\alpha/2}=Z_{0.025}=1.96\)</span> (95% confiabilidad)</li>
<li><span class="math inline">\(\alpha=0.01\)</span>, <span class="math inline">\(Z_{\alpha/2}=Z_{0.005}=2.58\)</span> (99% confiabilidad)</li>
</ul>
<p>Ejercicio, Se sabe que la vida en horas de una bombilla eléctrica de 75
watts se distribuye aproximadamente normal, con <span class="math inline">\(\sigma=25\)</span> horas. Una
muestra aleatoria de 20 bombillas tiene una vida media de <span class="math inline">\(\bar{X}=1014\)</span>
horas. Encontrarlos intervalos de confianza para 90, 95 y 99 % de
confiabilidad</p>
<p>Solución, como información <span class="math inline">\(n=20\)</span>, para elaborar los intervalos:</p>
<p><span class="math display">\[\bar{X}-Z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\leq\mu \leq \bar{X}+Z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\]</span>
Al 90%</p>
<p><span class="math display">\[1014-1.64 \frac{25}{\sqrt{20}}\leq\mu \leq 1014+1.64 \frac{25}{\sqrt{20}}\]</span></p>
<p><span class="math display">\[1004.832 \leq \mu \leq 1023.168\]</span> Al 95%</p>
<p><span class="math display">\[1014-1.96 \frac{25}{\sqrt{20}}\leq\mu \leq 1014+1.96 \frac{25}{\sqrt{20}}\]</span></p>
<p><span class="math display">\[1003.043 \leq \mu \leq 1024.957\]</span> Al 99%</p>
<p><span class="math display">\[1014-2.58 \frac{25}{\sqrt{20}}\leq\mu \leq 1014+2.58 \frac{25}{\sqrt{20}}\]</span></p>
<p><span class="math display">\[999.5774 \leq \mu \leq 1028.423\]</span></p>
<div id="tamaño-de-muestra" class="section level4" number="3.3.1.1">
<h4><span class="header-section-number">3.3.1.1</span> Tamaño de muestra</h4>
<p>Definamos al margen de error absoluto como:</p>
<p><span class="math display">\[\epsilon=Z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\]</span> Notar que es posible
despejar <span class="math inline">\(n\)</span> y esto permitirá tener una formula para definir un tamaño
de muestra condicionado a: el margen de error (<span class="math inline">\(\epsilon\)</span>), desviación
de los datos (<span class="math inline">\(\sigma\)</span>) y el nivel de confiabilidad (<span class="math inline">\(Z_{\alpha/2}\)</span>)</p>
<p><span class="math display">\[n=\frac{Z_{\alpha/2}^2*\sigma^2}{\epsilon^2}=\left(\frac{Z_{\alpha/2}*\sigma}{\epsilon} \right)^2\]</span>
Nota: Esta formula se puede utilizar en la medida que la muestra que se
seleccione sea aleatoria simple, se refiere a la selección de unidades
simples.</p>
<p>Ejemplo, se busca conocer el tiempo promedio en horas/día que pasan los
estudiantes de informática de la UMSA en la computadora, para ello se
planea realizar una encuesta aleatoria, que logre un 95% de
confiabilidad y tenga un margen de error de 0.8 horas. Definir el tamaño
de muestra necesario.</p>
<p>Solución, como información se tiene: <span class="math inline">\(\epsilon=0.8\)</span>,
<span class="math inline">\(Z_{\alpha/2}=1.96\)</span>, para el valor de <span class="math inline">\(\sigma\)</span> para el calculo del
tamaño de muestra se realizó una piloto en la materia de estadística II
a 10 estudiantes y el resultado fue <span class="math inline">\(\sigma=3.335\)</span>. Así:</p>
<p><span class="math display">\[n=\left(\frac{1.96*3.335}{0.8} \right)^2=66.8\approx 67\]</span> ###
Intervalo de confianza sobre la diferencia de dos medias, conocida la
varianza</p>
<p>Tenemos dos va independientes, <span class="math inline">\(X_1\)</span> con media <span class="math inline">\(\mu_1\)</span> desconocida y
varianza <span class="math inline">\(\sigma^2_1\)</span> conocida y <span class="math inline">\(X_2\)</span> con media <span class="math inline">\(\mu_2\)</span> desconocida y
varianza <span class="math inline">\(\sigma^2_2\)</span> conocida. El objetivo es encontrar un intervalo
para <span class="math inline">\(\mu_1-\mu2\)</span>. Sea dos muestras aleatorias recopíladas para ambas
va, de tal forma que <span class="math inline">\(n_1\)</span> representa el tamaño de muestra para <span class="math inline">\(X_1\)</span> y
<span class="math inline">\(n_2\)</span> para <span class="math inline">\(X_2\)</span>. Recordar por el teorema del limite central, esta
diferencia de medias puede ser estimada por sus medias muestrales y
además se aproxima a una normal, tal que:</p>
<p><span class="math display">\[\bar{X}_1-\bar{X}_2 \sim N\left(\mu_{\bar{X}_1-\bar{X}_2}=\mu_1-\mu_2,\sigma^2_{\bar{X}_1-\bar{X}_2}=\frac{\sigma^2_1}{n_1}+\frac{\sigma^2_2}{n_2}\right)\]</span>
Ahora,</p>
<p><span class="math display">\[Z=\frac{\bar{X}_1-\bar{X}_2-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma^2_1}{n_1}+\frac{\sigma^2_2}{n_2}}}\]</span>
Dado que <span class="math inline">\(Z\sim N(0,1)\)</span>, ahora lo que queda es trabajar sobre:</p>
<p><span class="math display">\[P(-Z_{\alpha/2} \leq Z \leq Z_{\alpha/2})=1-\alpha\]</span> Así, el limite
inferior y superior esta dado por:</p>
<p><span class="math display">\[L=\bar{X}_1-\bar{X}_2-Z_{\alpha/2}\sqrt{\frac{\sigma^2_1}{n_1}+\frac{\sigma^2_2}{n_2}}\]</span>
<span class="math display">\[U=\bar{X}_1-\bar{X}_2+Z_{\alpha/2}\sqrt{\frac{\sigma^2_1}{n_1}+\frac{\sigma^2_2}{n_2}}\]</span></p>
<p>Notar que en general, dado un estimador <span class="math inline">\(\hat{\theta}\)</span> para el parámetro
<span class="math inline">\(\theta\)</span>, su usamos el teorema del limite central su intervalo de
confianza estará dado por:</p>
<p><span class="math display">\[IC(\theta): \quad \hat{\theta} \pm Z_{\alpha/2} \sqrt{V(\hat{\theta})} \]</span></p>
<p>Ejercicio: Se lleva a cabo pruebas de resistencia a la tensión sobre
diferentes clases de largueros de aluminio utilizados en la fabricación
de alas de aeroplanos comerciales. De la experiencia pasada con el
proceso de fabricación de largueros y del procedimiento de prueba, se
supone que las desviaciones estándar de las resistencias a la tensión
son conocidas, Los datos obtenidos son:</p>
<ul>
<li>Clase de larguero 1: <span class="math inline">\(n_1=18\)</span>, <span class="math inline">\(\bar{X}_1=85.9\)</span>, <span class="math inline">\(\sigma_1=1\)</span></li>
<li>Clase de larguero 2: <span class="math inline">\(n_2=16\)</span>, <span class="math inline">\(\bar{X}_2=73.3\)</span>, <span class="math inline">\(\sigma_2=1.5\)</span></li>
</ul>
<p>Si <span class="math inline">\(\mu_1\)</span> y <span class="math inline">\(\mu_2\)</span> son las verdaderas resistencias a la tensión de
ambas clases de largueros. Encuentre intervalos de confianza al 90% y
95% de confiabilidad para la diferencia de estas medias.</p>
<p>Solución, para el 90% de confiabilidad el intervalo esta dado por:</p>
<p><span class="math display">\[IC_{90\%}(\mu_1-\mu_2): 85.9-73.3 \pm 1.64*\sqrt{\frac{1^2}{18}+\frac{1.5^2}{16}}=12.6 \pm 0.73: [11.87\quad 13.33]\]</span>
<span class="math display">\[IC_{90\%}(\mu_1-\mu_2): 85.9-73.3 \pm 1.96*\sqrt{\frac{1^2}{18}+\frac{1.5^2}{16}}=12.6 \pm 0.87: [11.73\quad 13.47]\]</span></p>
</div>
</div>
<div id="intervalo-de-confianza-para-la-media-y-la-diferencia-de-medias-con-varianza-desconocida-pero-muestra-mayor-a-30." class="section level3" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> Intervalo de confianza para la media y la diferencia de medias con varianza desconocida pero muestra mayor a 30.</h3>
<p>Para los 2 anteriores intervalos definidos se suponía que la varianza es
conocida, cuando no sucede esto la mejor alternativa para reemplazar a
<span class="math inline">\(\sigma^2\)</span> es usando <span class="math inline">\(\hat{S}^2\)</span>, esto siempre y cuando el tamaño de
muestra sea grande (<span class="math inline">\(n&gt;30\)</span>), para el caso de la diferencia de medias,
ambos tamaños de muestra deben ser mayores a 30 <span class="math inline">\((n_1,n_2&gt;30)\)</span>. Esto
debido al teorema del limite central.</p>
<p>Para la media</p>
<p><span class="math display">\[IC_{100(1-\alpha)}(\mu): \bar{X}\pm Z_{\alpha/2} \sqrt{\frac{\hat{S}^2}{n}}\]</span></p>
<p>Para la diferencia de medias</p>
<p><span class="math display">\[IC_{100(1-\alpha)}(\mu_1-\mu_2): \bar{X}_1-\bar{X}_2 \pm Z_{\alpha/2} \sqrt{\frac{\hat{S_1}^2}{n_1}+\frac{\hat{S_2}^2}{n_2}}\]</span></p>
<p>Ejercicio, se tiene el dato de una muestra aleatoria de 40 personas,
respecto su edad. Construya el intervalo de confianza al 95% de
confiabilidad. Los datos son:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1534</span>)</span>
<span id="cb90-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb90-2" aria-hidden="true" tabindex="-1"></a>x<span class="ot">&lt;-</span><span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">40</span>,<span class="dv">19</span>,<span class="dv">29</span>))</span>
<span id="cb90-3"><a href="estimaciones-de-una-y-dos-muestrales.html#cb90-3" aria-hidden="true" tabindex="-1"></a>x</span></code></pre></div>
<pre><code>##  [1] 20 26 25 24 22 27 21 28 23 26 23 24 27 22 20
## [16] 27 23 26 22 23 23 28 21 25 20 19 24 22 27 22
## [31] 21 28 28 24 23 24 21 28 27 24</code></pre>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x)<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span><span class="fl">1.96</span><span class="sc">*</span><span class="fu">sqrt</span>(<span class="fu">var</span>(x)<span class="sc">/</span><span class="dv">40</span>)</span></code></pre></div>
<pre><code>## [1] 23.12872 24.77128</code></pre>
</div>
<div id="intervamuestra-menor-a-30.lo-de-confianza-para-la-media-y-la-diferencia-de-medias-con-varianza-desconocida-pero" class="section level3" number="3.3.3">
<h3><span class="header-section-number">3.3.3</span> Intervamuestra menor a 30.lo de confianza para la media y la diferencia de medias con varianza desconocida pero</h3>
<p>Para producir un intervalo de confianza valido en estos casos, se debe
realizar supuestos fuertes respecto la población de la cual proviene la
información. La suposición mas usual es que la población de base viene
de una normal, lo que nos lleva en distribuciones muestrales a trabajar
con un distribución <span class="math inline">\(t-student\)</span>.</p>
<p>Para la media, sea:</p>
<p><span class="math display">\[t=\frac{\bar{X}-\mu}{\frac{\hat{S}}{\sqrt{n}}}\]</span></p>
<p>Ahora <span class="math inline">\(t\sim t-student(n-1)\)</span>, al igual que para la normal el objetivo es
encontrar:</p>
<p><span class="math display">\[P(L\leq t \leq U)=1-\alpha\]</span></p>
<p><span class="math display">\[P(-t_{\alpha/2,n-1} \leq t \leq t_{\alpha/2,n-1})=1-\alpha\]</span></p>
<p>Lo que nos a:</p>
<p><span class="math display">\[IC_{100*(1-\alpha)}(\mu): \bar{X} \pm t_{\alpha/2,n-1} \sqrt{\frac{\hat{S}^2}{n}}\]</span></p>
<p>Ejemplo, suponga que tenemos las mediciones de la estatura en cm de un
grupo de 20 personas que fue seleccionado de forma aleatoria de una
determinada población, los datos son:</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1421</span>)</span>
<span id="cb94-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb94-2" aria-hidden="true" tabindex="-1"></a>x<span class="ot">&lt;-</span><span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">20</span>,<span class="dv">140</span>,<span class="dv">180</span>))</span>
<span id="cb94-3"><a href="estimaciones-de-una-y-dos-muestrales.html#cb94-3" aria-hidden="true" tabindex="-1"></a>x</span></code></pre></div>
<pre><code>##  [1] 171 173 180 152 148 166 177 179 173 167 175
## [12] 145 152 142 143 155 179 176 173 147</code></pre>
<p>Encontrar un intervalo de confianza al 95% de confiabilidad para la
media poblacional.</p>
<p>Solución,</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb96-1" aria-hidden="true" tabindex="-1"></a>mx<span class="ot">&lt;-</span><span class="fu">mean</span>(x)</span>
<span id="cb96-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb96-2" aria-hidden="true" tabindex="-1"></a>ta<span class="ot">&lt;-</span><span class="fu">qt</span>(<span class="fl">0.05</span><span class="sc">/</span><span class="dv">2</span>,<span class="dv">19</span>,<span class="at">lower.tail =</span> F)</span>
<span id="cb96-3"><a href="estimaciones-de-una-y-dos-muestrales.html#cb96-3" aria-hidden="true" tabindex="-1"></a>s2<span class="ot">&lt;-</span><span class="fu">var</span>(x)</span>
<span id="cb96-4"><a href="estimaciones-de-una-y-dos-muestrales.html#cb96-4" aria-hidden="true" tabindex="-1"></a>n<span class="ot">&lt;-</span><span class="dv">20</span></span>
<span id="cb96-5"><a href="estimaciones-de-una-y-dos-muestrales.html#cb96-5" aria-hidden="true" tabindex="-1"></a>mx<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span>ta<span class="sc">*</span><span class="fu">sqrt</span>(s2<span class="sc">/</span>n)</span></code></pre></div>
<pre><code>## [1] 157.1698 170.1302</code></pre>
<p>Para la diferencia de medias, pero con varianzas iguales
<span class="math inline">\(\sigma_1=\sigma_2\)</span></p>
<p>Cuando <span class="math inline">\(n_1\)</span> o <span class="math inline">\(n_2\)</span> no superen ambas a 30, la mejor alternativa es usar
el intervalo de confianza en base a la distribución <span class="math inline">\(t\)</span>, para la
diferencia de medias el IC es:</p>
<p><span class="math display">\[IC_{100*(1-\alpha)}(\mu_1-\mu_2)=\bar{X}_1-\bar{X}_2+t_{\alpha/2,n_1+n_2-2} \hat{S}_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}\]</span>
Con <span class="math inline">\(\hat{S^2}_p\)</span></p>
<p><span class="math display">\[\hat{S}^2_p=\frac{(n_1-1)\hat{S}^2_1+(n_2-1)\hat{S}^2_2}{n_1+n_2-2}\]</span></p>
<p>Para la diferencia de medias, pero con varianzas no iguales</p>
<p><span class="math display">\[IC_{100*(1-\alpha)}(\mu_1-\mu_2)=\bar{X}_1-\bar{X}_2+t_{\alpha/2,v} \sqrt{\frac{\hat{S}_1^2}{n_1}+\frac{\hat{S}^2_2}{n_2}}\]</span></p>
<p><span class="math display">\[v=\frac{\left(\frac{\hat{S}_1^2}{n_1}+\frac{\hat{S}^2_2}{n_2} \right)^2}{\frac{(\hat{S}_1^2/n_1)^2}{n_1+1}+\frac{(\hat{S}^2_2/n_2)^2}{n_2+1}}\]</span>
Ejemplo, se tienen dos grupos donde se tomo de forma aleatoria a una
muestra de ambos grupos, con el fin de estudiar la diferencia de medias
para las notas de un examen, los resultados para ambos grupos fueron:</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1421</span>)</span>
<span id="cb98-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb98-2" aria-hidden="true" tabindex="-1"></a>x1<span class="ot">&lt;-</span><span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">10</span>,<span class="dv">1</span>,<span class="dv">100</span>))</span>
<span id="cb98-3"><a href="estimaciones-de-una-y-dos-muestrales.html#cb98-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1457</span>)</span>
<span id="cb98-4"><a href="estimaciones-de-una-y-dos-muestrales.html#cb98-4" aria-hidden="true" tabindex="-1"></a>x2<span class="ot">&lt;-</span><span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">13</span>,<span class="dv">1</span>,<span class="dv">100</span>))</span>
<span id="cb98-5"><a href="estimaciones-de-una-y-dos-muestrales.html#cb98-5" aria-hidden="true" tabindex="-1"></a>x1</span></code></pre></div>
<pre><code>##  [1] 79 82 99 30 20 64 94 97 84 67</code></pre>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb100-1" aria-hidden="true" tabindex="-1"></a>x2</span></code></pre></div>
<pre><code>##  [1] 73 62 57 23 59 16 65 39 81 23 74 22 20</code></pre>
<p>Armar un intervalo de confianza al 95% de confiabilidad suponiendo que
las varianzas son iguales y otro para varianzas distintas.</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb102-1" aria-hidden="true" tabindex="-1"></a>mx1<span class="ot">&lt;-</span><span class="fu">mean</span>(x1)</span>
<span id="cb102-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb102-2" aria-hidden="true" tabindex="-1"></a>mx2<span class="ot">&lt;-</span><span class="fu">mean</span>(x2)</span>
<span id="cb102-3"><a href="estimaciones-de-una-y-dos-muestrales.html#cb102-3" aria-hidden="true" tabindex="-1"></a>s21<span class="ot">&lt;-</span><span class="fu">var</span>(x1)</span>
<span id="cb102-4"><a href="estimaciones-de-una-y-dos-muestrales.html#cb102-4" aria-hidden="true" tabindex="-1"></a>s22<span class="ot">&lt;-</span><span class="fu">var</span>(x2)</span>
<span id="cb102-5"><a href="estimaciones-de-una-y-dos-muestrales.html#cb102-5" aria-hidden="true" tabindex="-1"></a>n1<span class="ot">&lt;-</span><span class="dv">10</span></span>
<span id="cb102-6"><a href="estimaciones-de-una-y-dos-muestrales.html#cb102-6" aria-hidden="true" tabindex="-1"></a>n2<span class="ot">&lt;-</span><span class="dv">13</span></span>
<span id="cb102-7"><a href="estimaciones-de-una-y-dos-muestrales.html#cb102-7" aria-hidden="true" tabindex="-1"></a>ta1<span class="ot">&lt;-</span><span class="fu">qt</span>(<span class="fl">0.025</span>,n1<span class="sc">+</span>n2<span class="dv">-2</span>,<span class="at">lower.tail =</span> F)</span>
<span id="cb102-8"><a href="estimaciones-de-una-y-dos-muestrales.html#cb102-8" aria-hidden="true" tabindex="-1"></a>s2p<span class="ot">&lt;-</span>((n1<span class="dv">-1</span>)<span class="sc">*</span>s21<span class="sc">+</span>(n2<span class="dv">-1</span>)<span class="sc">*</span>s22)<span class="sc">/</span>(n1<span class="sc">+</span>n2<span class="dv">-2</span>)</span>
<span id="cb102-9"><a href="estimaciones-de-una-y-dos-muestrales.html#cb102-9" aria-hidden="true" tabindex="-1"></a>v<span class="ot">&lt;-</span>((s21<span class="sc">/</span>n1<span class="sc">+</span>s22<span class="sc">/</span>n2)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(((s21<span class="sc">/</span>n1)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(n1<span class="sc">+</span><span class="dv">1</span>)<span class="sc">+</span>((s22<span class="sc">/</span>n2)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(n2<span class="sc">+</span><span class="dv">1</span>))</span>
<span id="cb102-10"><a href="estimaciones-de-una-y-dos-muestrales.html#cb102-10" aria-hidden="true" tabindex="-1"></a>ta2<span class="ot">&lt;-</span><span class="fu">qt</span>(<span class="fl">0.025</span>,v,<span class="at">lower.tail =</span> F)</span>
<span id="cb102-11"><a href="estimaciones-de-una-y-dos-muestrales.html#cb102-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Intervalo con varianzas iguales</span></span>
<span id="cb102-12"><a href="estimaciones-de-una-y-dos-muestrales.html#cb102-12" aria-hidden="true" tabindex="-1"></a>mx1<span class="sc">-</span>mx2<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span>ta1<span class="sc">*</span><span class="fu">sqrt</span>(s2p)<span class="sc">*</span><span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">/</span>n1<span class="sc">+</span><span class="dv">1</span><span class="sc">/</span>n2)</span></code></pre></div>
<pre><code>## [1]  2.132725 46.605736</code></pre>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Intervalo con varianzas desiguales</span></span>
<span id="cb104-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb104-2" aria-hidden="true" tabindex="-1"></a>mx1<span class="sc">-</span>mx2<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span>ta2<span class="sc">*</span><span class="fu">sqrt</span>(s21<span class="sc">/</span>n1<span class="sc">+</span>s22<span class="sc">/</span>n2)</span></code></pre></div>
<pre><code>## [1]  1.793795 46.944667</code></pre>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="co">#estimador puntual</span></span>
<span id="cb106-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb106-2" aria-hidden="true" tabindex="-1"></a>mx1<span class="sc">-</span>mx2</span></code></pre></div>
<pre><code>## [1] 24.36923</code></pre>
</div>
<div id="intervalos-de-confianza-para-la-diferencia-de-medias-de-datos-pareados" class="section level3" number="3.3.4">
<h3><span class="header-section-number">3.3.4</span> Intervalos de confianza para la diferencia de medias de datos pareados</h3>
<p>En general, supongamos que los datos constan de <span class="math inline">\(n\)</span> pares
<span class="math inline">\((X_{11}, X_{21}), (X_{12}, X_{22})...(X_{1n}, X_{2n})\)</span>, usualmente esto
sucede cuando se trabaja con observaciones en 2 puntos distintos de
tiempo. Definamos las diferencias como
<span class="math inline">\(D_1=X_{11}-X_{21},D_2=X_{12}-X{22},\ldots,D_n=X_{1n}-X_{2n}\)</span>,
estableciendo a <span class="math inline">\(D\)</span> como la va, su intervalo es:</p>
<p><span class="math display">\[IC_{100*(1-\alpha)}(\mu_D=\mu_1-\mu_2): \bar{D} \pm t_{\alpha/2,n-1}*\sqrt{\frac{\hat{S}^2_D}{n}} \]</span></p>
<p>Si n es grande, entonces el intervalo es dado por:</p>
<p><span class="math display">\[IC_{100*(1-\alpha)}(\mu_D=\mu_1-\mu_2): \bar{D} \pm Z_{\alpha/2}*\sqrt{\frac{\hat{S}^2_D}{n}} \]</span></p>
<p>Ejemplo, se tiene las notas de los parciales de una muestra de 12
estudiantes, será que los estudiantes mejoraron su rendimiento del
parcial 1 al parcial 2. Construya un intervalo de confianza al 90%.</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb108-1" aria-hidden="true" tabindex="-1"></a>bd<span class="ot">&lt;-</span><span class="fu">data.frame</span>(<span class="at">id=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>,<span class="at">p1=</span><span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">12</span>,<span class="dv">40</span>,<span class="dv">80</span>)),<span class="at">p2=</span><span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">12</span>,<span class="dv">30</span>,<span class="dv">90</span>)))</span>
<span id="cb108-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb108-2" aria-hidden="true" tabindex="-1"></a>bd<span class="sc">$</span>D<span class="ot">&lt;-</span>bd<span class="sc">$</span>p1<span class="sc">-</span>bd<span class="sc">$</span>p2</span>
<span id="cb108-3"><a href="estimaciones-de-una-y-dos-muestrales.html#cb108-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(bd<span class="sc">$</span>D)<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span><span class="fu">qt</span>(<span class="fl">0.05</span>,<span class="dv">11</span>,<span class="at">lower.tail =</span> F)<span class="sc">*</span><span class="fu">sqrt</span>(<span class="fu">var</span>(bd<span class="sc">$</span>D)<span class="sc">/</span><span class="dv">12</span>)</span></code></pre></div>
<pre><code>## [1] -12.359681   9.193015</code></pre>
</div>
<div id="intervalo-de-confianza-para-proporciones" class="section level3" number="3.3.5">
<h3><span class="header-section-number">3.3.5</span> Intervalo de confianza para proporciones</h3>
<p>Si asumimos que el estimador del parámetro <span class="math inline">\(P\)</span> (proporción), se
distribuye normal, es decir, <span class="math inline">\(\hat{P}\sim Normal\)</span>, bajo ciertas
condiciones como que el tamaño de muestra es grande, se puede plantear
al intervalo de confianza como:</p>
<p><span class="math display">\[IC_{100*(1-\alpha)}(P)=\hat{P} \pm Z_{\alpha/2} * \sqrt{V(\hat{P})}\]</span>
Donde para encontrar la <span class="math inline">\(V(\hat{P})\)</span> basta con resolver la varianza del
estimador de la media para valores binarios.</p>
<p><span class="math display">\[V(\bar{X})=\frac{\sigma^2}{n} =V(\hat{P})=\frac{\sigma^2_p}{n}=\frac{1}{n}\left(\frac{\sum_{i=1}^N x_i^2 }{N}-\mu^2 \right)=\frac{1}{n}\left(\frac{\sum_{i=1}^N x_i }{N}-P^2 \right)=\]</span></p>
<p><span class="math display">\[=\frac{1}{n}(P-P^2)=\frac{P(1-P)}{n}\]</span></p>
<p>Notar que esta varianza esta en términos del parámetro <span class="math inline">\(P\)</span>, por lo que
recurrimos en el caso muestral a reemplazarlo por su estimador
<span class="math inline">\(\hat{P}\)</span>. Así, el intervalo de confianza queda como:</p>
<p><span class="math display">\[IC_{100*(1-\alpha)}(P)=\hat{P} \pm Z_{\alpha/2} * \sqrt{\frac{\hat{P}(1-\hat{P})}{n}}\]</span></p>
<p>Ejemplo, en un curso se tomo una muestra aleatoria de 15 personas,
respecto su estatura en centímetros, las mediciones son:</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1501</span>)</span>
<span id="cb110-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb110-2" aria-hidden="true" tabindex="-1"></a>x<span class="ot">&lt;-</span><span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">15</span>,<span class="dv">165</span>,<span class="dv">10</span>),<span class="dv">0</span>)</span>
<span id="cb110-3"><a href="estimaciones-de-una-y-dos-muestrales.html#cb110-3" aria-hidden="true" tabindex="-1"></a>x</span></code></pre></div>
<pre><code>##  [1] 161 179 171 152 141 168 168 173 155 169 160
## [12] 177 164 165 159</code></pre>
<p>Se pide encontrar al estimador de la proporción y su intervalo de
confianza al 95% de confiabilidad para la proporción de estudiantes con
estatura de 170 o más.</p>
<p>Solución,</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb112-1" aria-hidden="true" tabindex="-1"></a>n<span class="ot">&lt;-</span><span class="dv">15</span></span>
<span id="cb112-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb112-2" aria-hidden="true" tabindex="-1"></a>x<span class="ot">&lt;-</span>(x<span class="sc">&gt;=</span><span class="dv">170</span>)<span class="sc">*</span><span class="dv">1</span></span>
<span id="cb112-3"><a href="estimaciones-de-una-y-dos-muestrales.html#cb112-3" aria-hidden="true" tabindex="-1"></a>x</span></code></pre></div>
<pre><code>##  [1] 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0</code></pre>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="co">#el estimador de la proporción</span></span>
<span id="cb114-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb114-2" aria-hidden="true" tabindex="-1"></a>p<span class="ot">&lt;-</span><span class="fu">mean</span>(x)</span>
<span id="cb114-3"><a href="estimaciones-de-una-y-dos-muestrales.html#cb114-3" aria-hidden="true" tabindex="-1"></a>p</span></code></pre></div>
<pre><code>## [1] 0.2666667</code></pre>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="co">#en porcentaje</span></span>
<span id="cb116-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb116-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x)<span class="sc">*</span><span class="dv">100</span></span></code></pre></div>
<pre><code>## [1] 26.66667</code></pre>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co">#intervalo</span></span>
<span id="cb118-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb118-2" aria-hidden="true" tabindex="-1"></a>p<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span><span class="fl">1.96</span><span class="sc">*</span><span class="fu">sqrt</span>(p<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">/</span>n)</span></code></pre></div>
<pre><code>## [1] 0.04287417 0.49045916</code></pre>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="co">#p-1.96*sqrt(p*(1-p)/n)</span></span>
<span id="cb120-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb120-2" aria-hidden="true" tabindex="-1"></a><span class="co">#p+1.96*sqrt(p*(1-p)/n)</span></span>
<span id="cb120-3"><a href="estimaciones-de-una-y-dos-muestrales.html#cb120-3" aria-hidden="true" tabindex="-1"></a><span class="co">#intervalo en %</span></span>
<span id="cb120-4"><a href="estimaciones-de-una-y-dos-muestrales.html#cb120-4" aria-hidden="true" tabindex="-1"></a>(p<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span><span class="fl">1.96</span><span class="sc">*</span><span class="fu">sqrt</span>(p<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">/</span>n))<span class="sc">*</span><span class="dv">100</span></span></code></pre></div>
<pre><code>## [1]  4.287417 49.045916</code></pre>
<div id="tamaño-de-muestra-para-estimar-proporciones" class="section level4" number="3.3.5.1">
<h4><span class="header-section-number">3.3.5.1</span> Tamaño de muestra para estimar proporciones</h4>
<p>Para la proporción definimos el margen de error (<span class="math inline">\(\epsilon\)</span>) como:</p>
<p><span class="math display">\[\epsilon= Z_{\alpha/2} * \sqrt{\frac{\hat{P}(1-\hat{P})}{n}}\]</span> Ahora,
podemos usar esta definición como una salida para el calculo del tamaño
de muestra necesario para cometer un determinado margen de error
(<span class="math inline">\(epsilon\)</span>), sujeto a un nivel de confiabilidad de <span class="math inline">\(Z_{\alpha/2}\)</span>, basta
con despejar <span class="math inline">\(n\)</span> de la anterior formula.</p>
<p><span class="math display">\[n=\left(\frac{Z_{\alpha/2}}{\epsilon}\right)^2 \hat{P}(1-\hat{P})\]</span>
Dado que definir el tamaño de muestra es un paso previo a la recolección
de información, notar que se tiene total control sobre el margen de
error (<span class="math inline">\(\epsilon\)</span>) y el nivel de confiabilidad (<span class="math inline">\(Z_{\alpha/2}\)</span>), sin
embargo, en la formula aparece el estimador <span class="math inline">\(\hat{P}\)</span> que es el de
interés, la solución para saltarnos este dilema, es elegir un <span class="math inline">\(\hat{P}\)</span>
basado en un estudio similar o una prueba piloto, la otra alternativa
extrema es suponer un <span class="math inline">\(\hat{P}\)</span> que haga máximo a <span class="math inline">\(n\)</span> con lo demás fijo.</p>
<p>Ejercicio, una carrera en la universidad esta a punto de elegir a sus
autoridades, se busca hacer una encuesta de intención de votos en los
estudiantes para el candidato <span class="math inline">\(Z\)</span>, se quiere un nivel de confianza del
95%, y no errar en +- 5%. Calcular el tamaño de muestra, (1) suponiendo
<span class="math inline">\(n\)</span> máxima y (2) mediante un sondeo se verifico que el candidato <span class="math inline">\(Z\)</span>
tiene un 70% de apoyo.</p>
</div>
</div>
<div id="intervalo-de-confianza-para-diferencia-de-proporciones" class="section level3" number="3.3.6">
<h3><span class="header-section-number">3.3.6</span> Intervalo de confianza para diferencia de proporciones</h3>
<p>Esta diferencia de proporciones son ampliamente usadas cuando se comparan dos poblaciones, respecto una característica de interés sobre dos poblaciones independientes. Así el intervalo de la diferencia de proporciones esta dado por:</p>
<p><span class="math display">\[IC_{100*(1-\alpha)}(P_1-P_2)=(\hat{P}_1-\hat{P}_2) \pm Z_{\alpha/2} * \sqrt{\frac{\hat{P_1}(1-\hat{P}_1)}{n_1}+\frac{\hat{P}_2(1-\hat{P}_2)}{n_2}}\]</span></p>
<p>Donde <span class="math inline">\(\hat{P}_1\)</span> y <span class="math inline">\(\hat{P}_2\)</span> son estimaciones de proporción para la población 1 y 2, respecto una misma característica, <span class="math inline">\(n_1\)</span> y <span class="math inline">\(n_2\)</span> son los tamaños de muestra es estas poblaciones.</p>
<p>Ejercicio, en una muestra aleatoria de 20 estudiantes se midió la estatura del grupo, se tiene conocimiento del sexo de los estudiantes y se busca estimar la diferencia de proporciones por hombre y mujer de la proporción de estudiantes que superan los 170 cm de estatura. Los datos son:</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="estimaciones-de-una-y-dos-muestrales.html#cb122-1" aria-hidden="true" tabindex="-1"></a>n<span class="ot">&lt;-</span><span class="dv">20</span></span>
<span id="cb122-2"><a href="estimaciones-de-una-y-dos-muestrales.html#cb122-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1501</span>)</span>
<span id="cb122-3"><a href="estimaciones-de-una-y-dos-muestrales.html#cb122-3" aria-hidden="true" tabindex="-1"></a>estatura<span class="ot">&lt;-</span><span class="fu">round</span>(<span class="fu">rnorm</span>(n,<span class="dv">165</span>,<span class="dv">10</span>),<span class="dv">0</span>)</span>
<span id="cb122-4"><a href="estimaciones-de-una-y-dos-muestrales.html#cb122-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1501</span>)</span>
<span id="cb122-5"><a href="estimaciones-de-una-y-dos-muestrales.html#cb122-5" aria-hidden="true" tabindex="-1"></a>mujer<span class="ot">&lt;-</span><span class="fu">rbinom</span>(n,<span class="dv">1</span>,<span class="fl">0.4</span>)</span>
<span id="cb122-6"><a href="estimaciones-de-una-y-dos-muestrales.html#cb122-6" aria-hidden="true" tabindex="-1"></a>bd<span class="ot">&lt;-</span><span class="fu">data.frame</span>(estatura,mujer)</span>
<span id="cb122-7"><a href="estimaciones-de-una-y-dos-muestrales.html#cb122-7" aria-hidden="true" tabindex="-1"></a>bd</span></code></pre></div>
<pre><code>##    estatura mujer
## 1       161     0
## 2       179     0
## 3       171     1
## 4       152     0
## 5       141     1
## 6       168     0
## 7       168     0
## 8       173     1
## 9       155     0
## 10      169     0
## 11      160     1
## 12      177     1
## 13      164     1
## 14      165     1
## 15      159     1
## 16      172     1
## 17      158     0
## 18      169     0
## 19      172     1
## 20      166     0</code></pre>
<p>Se pide calcular el estimador puntual de la diferencia de proporciones y el intervalo de confianza al 90% de confiabilidad.</p>
<p>Solución, algunos parámetros del ejercicio <span class="math inline">\(n_1=10\)</span> , <span class="math inline">\(n_2=10\)</span>, las proporciones:</p>
<p><span class="math display">\[\hat{P}_{1,h}=\frac{\#a}{n_1}=\frac{1}{10}=0.1\]</span>
<span class="math display">\[\hat{P}_{2,m}=\frac{\#a}{n_2}=\frac{5}{10}=0.5\]</span></p>
<p>El estimador puntual es dado por:</p>
<p><span class="math display">\[\hat{P}_1-\hat{P}_2=0.1-0.5=-0.4\]</span></p>
<p>Ahora, el intervalo de confianza</p>
<p><span class="math display">\[IC_{100*(1-\alpha)}(P_1-P_2)=-0.4 \pm 1.64 * \sqrt{\frac{0.1*0.9}{10}+\frac{0.5*0.5}{10}}=-0.4 \pm 0.3024\]</span>
<span class="math display">\[IC_{100*(1-\alpha)}(P_1-P_2)=[-0.702 \quad -0.098]\]</span></p>
</div>
<div id="intervalo-de-confianza-para-la-varianza" class="section level3" number="3.3.7">
<h3><span class="header-section-number">3.3.7</span> Intervalo de confianza para la varianza</h3>
<p>Suponga que <span class="math inline">\(X\sim Normal(\mu,\sigma)\)</span> ambos parámetros desconocidos. Sea <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span> una muestra aleatoria de tamaño <span class="math inline">\(n\)</span> de <span class="math inline">\(X\)</span>. Recodar que la varianza muestra sigue una distribución de muestreo tipo <span class="math inline">\(\chi^2\)</span>.</p>
<p><span class="math display">\[\chi^2=\frac{(n-1)\hat{S}^2}{\sigma^2}\]</span>
Para desarrollar el intervalo usamos esta distribución:</p>
<p><span class="math display">\[P(\chi^2_{1-\alpha/2,n-1} \leq \chi^2 \leq \chi^2_{\alpha/2,n-1})=1-\alpha\]</span>
<span class="math display">\[IC_{100*(1-\alpha)}(\sigma^2): \left[\frac{(n-1)\hat{S}^2}{\chi^2_{\alpha/2,n-1}} \quad  \frac{(n-1)\hat{S}^2}{\chi^2_{1-\alpha/2,n-1}}\right]\]</span></p>
</div>
<div id="intervalo-de-confianza-para-el-cociente-de-varianzas" class="section level3" number="3.3.8">
<h3><span class="header-section-number">3.3.8</span> Intervalo de confianza para el cociente de varianzas</h3>
<p>El objetivo de esta medida es tener un intervalo para el cociente de las varianzas de dos poblaciones, esto puede servir para identificar que población (con que variable) tiene mayor variabilidad. El parámetro es:</p>
<p><span class="math display">\[\theta=\frac{\sigma^2_1}{\sigma^2_2}\]</span>
Supongamos que <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> son va normales con media <span class="math inline">\(\mu_1\)</span> y <span class="math inline">\(\mu_2\)</span> desconocidas y varianzas <span class="math inline">\(\sigma^2_1\)</span>, <span class="math inline">\(\sigma^2_2\)</span> también desconocidas. Sean dos muestras aleatorias de <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> de tamaño <span class="math inline">\(n_1\)</span> y <span class="math inline">\(n_2\)</span> y sean <span class="math inline">\(\hat{S}^2_1\)</span> y <span class="math inline">\(\hat{S}^2_2\)</span> las varianzas de las muestras. Para armar el intervalo de confianza recurrimos a la distribución <span class="math inline">\(F\)</span>.</p>
<p><span class="math display">\[F=\frac{\frac{\hat{S}^2_2}{\sigma^2_2}}{\frac{\hat{S}^2_1}{\sigma^2_1}}\]</span></p>
<p>Se busca:</p>
<p><span class="math display">\[P(F_{1-\alpha/2,n_1-1,n_2-1} \leq F \leq F_{\alpha/2,n_1-1,n_2-1})=1-\alpha\]</span></p>
<p><span class="math display">\[IC_{100*(1-\alpha)}\left(\frac{\sigma^2_1}{\sigma^2_2}\right): \left[\frac{\hat{S}^2_1}{\hat{S}^2_2} F_{1-\alpha/2,n_1-1,n_2-1} \quad \frac{\hat{S}^2_1}{\hat{S}^2_2} F_{\alpha/2,n_1-1,n_2-1}\right]\]</span></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tema-2-distribuciones-muestrales.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="prueba-de-hipótesis.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
