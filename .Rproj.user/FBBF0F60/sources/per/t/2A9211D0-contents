# Tema 2: Distribuciones muestrales

A partir de este tema la estadística esta vinculada con la *inferencia* sobre los *parámetros* de la información/datos.

## Muestras y población

> Definición: Una población es una colección "completa" de objetos, estos objetos tienen variables.

Sea nuestra población $U$, esta población puede ser finita o infinita

$$U=\{u_1, u_2, \ldots , u_i,...,u_N \}$$

$$U=\{u_1, u_2, \ldots , u_i,... \}$$

Cada elemento de $U$ tiene *variables* o características asociadas:

$$u_i=\{X_{i1}, X_{i2}, \ldots, X_{iP} \}$$
$$u_j=\{X_{j1}, X_{j2}, \ldots, X_{jP} \}$$

> Definición, Muestra: Una muestra es un subconjunto de U.

$$s \subset U ,\quad s \in U \quad $$
Donde $s$ representa al conjunto denominado "muestra"

Normalmente una muestra tiene un tamaño $n$ (puede ser **fijo** y aleatorio), el mecanismo para obtener la muestra de $U$ puede ser con reposición o sin reposición, en
cualquier caso podemos anotar esto de la siguiente forma, sea $s$ una muestra:

$$s=\{u_{1}^*,u_2^*, \ldots, u_n^*\}$$ 
En un caso extremo para el muestreo con reposición

$$u_i^*=u_j^* \quad i,j=1, \ldots ,n$$

Note que los elementos $u_1$ y $u_1^*$ no necesariamente son los mismos. 

Una característica ideal al momento de obtener la muestra, es que todos los elementos de la población tengan alguna probabilidad de ser parte de la muestra. (Esto depende del esquema de selección)

El subconjunto $s$ no es único y en realidad existen muchas muestras posibles, según el contexto, esto depende:

  - Del tamaño de $N$, $n$
  - Del mecanismo s/rep, c/rep.

Ejemplo,

1.  Sea la población $U=\{a,b,c,d,e,f\}$, se define una muestra de $n=3$, escriba todas las muestras posibles según ambos mecanismos de reposición.

Solución,

  - (s/rep), 20: $s_1=\{a,b,c\}$, $s_2=\{a,b,d \}$, $\ldots$
    ,$s_{20}=\{d,e,f\}$
  - (c/rep), 216: $s_1=\{a,a,a\}$, $s_2=\{a,a,b\}$, $\ldots$,
    $s_{216}=\{f,f,f\}$

```{r}
N<-6;n<-3
choose(N,n)
U<-c("a","b","c","d","e","f")
combn(U,n)
N^n
```

  2. En una población de 58 estudiantes, si se define una muestra de 15 estudiantes, según ambos mecanismos de selección ¿Cuántas muestras se pueden armar?

  + (s/r) `r choose(58,15)``
  + (c/r) `r 58^15` Doscientos ochenta y dos cuatrillones setecientos sesenta y un mil doscientos cincuenta y seis trillones ochocientos ochenta y un mil doscientos noventa y siete billones trescientos tres mil setecientos seis millones seiscientos sesenta y seis mil cuatrocientos cuatro
  
  3. En la carrera de informática de la UMSA se planea realizar una encuesta de opinión con una muestra de 500 estudiantes, según ambos mecanismos de selección ¿Cuántas muestras se pueden armar? (Suponer que $N=2500$)
  
  + (s/r, c/r) Es un número muy grande. Para s/r son 542 dígitos

Sin reposición:

$$Muestras_{Posibles}=\binom{N}{n}$$

Con reposición:

$$Muestras_{Posibles}=N^n$$

Imaginemos a la primera variable de interés $X_1$, para el universo esta variable tiene los elementos:

$$X_1=\{X_{11}, X_{21}, X_{31}, \ldots, X_{N1} \}$$

Imaginemos que observamos a $X_1$, para la muestra.

$$X_1^*=\{X_{11}^*, X_{21}^*, X_{31}^*, \ldots, X_{n1}^* \}$$

Estos $X_{i1}^*$ para los $i=1,\ldots,n$ son variables aleatorias. Por lo tanto $X_1^*$ es un vector aleatorio de tamaño $n$.

De ahora en adelante vamos a trabajar con un solo vector aleatorio denominado $X$, de tal forma que este sea la colección de $n$ variables aleatorias.

$$X=\{X_1,X_2,\ldots,X_n \}$$

> Definición.

La colección del vector aleatorio $X=\{X_1,X_2,\ldots,X_n \}$, son independientes e idénticamente distribuidas (iid) si la distribución conjunta de las $n$ variables puede ser escrita como: 

$$f(x_1,x_2,\ldots,x_n)=f(x_1)*f(x_2)*\ldots*f(x_n)$$ 

y además todas las $x_i$ tienen la misma función de distribución $F(x)$.

> Definición

Sea $N$ el tamaño de la población y $n$ el tamaño de la muestra, ambos valores para fines de este capítulo son constantes.

## Parámetros, estadísticas y estimadores.

El objetivo de la estadística es aprender acerca de las características de una población. Estas características las vamos a llamar *parámetros*.

> Definición,

Un parámetro $\theta$ es una **función** sobre la población $U$.

$$\theta=f(U,X,Y,Z,\ldots)$$

Nota: Los parámetros de una población son constantes.

Los parámetros más usuales son, el total, la media, la proporción, la varianza, las razones. 

> Ejemplo, 

Sea el universo los 10 primeros números naturales y sus valores. $Y=\{1,2,3,4,5,6,7,8,9,10\}$. Sobre estos valores de esta población de $N=10$ se pueden calcular los siguientes parámetros.

-   Total

$$\theta_1=t_y=\sum_U y_i=55$$

-   Media

$$\theta_2=\mu_y=\frac{t_y}{N}=\frac{55}{10}=5.5$$

-   Máximo: $\theta_3=max(y)=10$
-   Mínimo: $\theta_4=min(y)=1$

- Proporción

$$P_{pares}=\frac{5}{10}=0.5$$

Es posibles hacer transformaciones sobre $Y$, sea $Z$ una variables binaria que identifique a los números primos de $Y$; $1=primo$, $0=\sim primo$

$$Z=\{1,1,1,0,1,0,1,0,0,0 \}$$

Calcular el promedio de $Z$

$$\theta_5=\mu_z=\frac{5}{10}=0.5$$

Cuando obtenemos la media de un vector binario, obtenemos lo que se denomina un proporción.

$$\theta_5=P_a=\frac{\#A}{N}$$

$$\theta_5=P_{primos}=\frac{\#primos}{N}$$

-   Diferencias de medias: asume que tenemos a 2 poblaciones de interés,
    de tamaño $N_1$ y $N_2$

$$\theta_6=\mu_1-\mu_2$$

-   Diferencias de proporciones: asume que tenemos a 2 poblaciones de interés, de tamaño $N_1$ y $N_2$

$$\theta_7=P_1-P_2$$

> Definición, estadística

Se denomina **estadística** a una **función** sobre la muestra.

> Definición, estimador

$$Aleatorio\quad:f(s,X)=\hat{\theta} \rightarrow \theta=f(U,X): \quad fijo$$

Un estimador $\hat{\theta}$ para el parámetro $\theta$ es una
**estadística** que busca aproximar/adivinar el valor de $\theta$

> Ejemplo 

Imaginemos una población de 10 estudiantes sobre la cuales nos interesa conocer el gasto diario en pasajes a la universidad (pasaje ida y vuelta desde su casa al monoblock), para ello se planea tomar una muestra de 3 estudiantes. 

El objetivo de este estudio es conocer el gasto total de estos 10 estudiantes.

Sea $y_i$ la variable gasto es pasajes del estudiante $i$. 

$$\theta=t_y=\sum_U y_i=\sum_{i=1}^{10} y_i$$

```{r}
N<-10
y<-c(5.2,6,8,10,3,4,7,4,4,10.5)
ty<-sum(y)#parámetro
```

Ahora vamos a obtener una muestra de tamaño 3 de esta población. (s/rep)

```{r}
n<-3
choose(10,3)#muestra posibles
set.seed(1439)#semilla
ys<-sample(y,n)
ys
```

$$\hat{\theta}_1=\hat{t}_y=\frac{\prod_s y_i}{n}=54.6$$

$$\hat{\theta}_2=N*\frac{\sum_s y_i}{n}=62.3$$

$$\hat{\theta}_3=y_{min}+\prod_{s(-y_{min})}y_i=57.6$$

$$\hat{\theta}_4=n\sum_s y_i=56.1$$

> Nota, el estimador hace referencia a la función matemática, mientras que una estimación es una evaluación de esa función matemática usando la muestra seleccionada.

```{r}
s<-combn(y,n)#muestras posibles
#theta1
et1<-apply(s,2,prod)/n
#theta2
et2<-N*apply(s, 2,mean)
#theta4
et4<-n*apply(s, 2,sum)

par(mfrow=c(2,2))
plot(density(et1),"theta1",xlim=c(0,150))
abline(v=ty,col="red")

plot(density(et2),"theta2",xlim=c(0,150))
abline(v=ty,col="red")

plot(density(et4),"theta4",xlim=c(0,150))
abline(v=ty,col="red")

dev.off()
e1<-sum(et1*(1/120))
e2<-sum(et2*(1/120))
e4<-sum(et4*(1/120))

sum(((et1-e1)^2)*(1/120))
sum(((et2-e2)^2)*(1/120))
sum(((et4-e4)^2)*(1/120))
```

$$E[X]=\sum_{Rx}x*P(X=x)$$

$$E[\hat{\theta}]=\theta$$

## Distribución muestral

Recordar que una estadística es una función sobre la muestra y sobre los valores que toman las variables aleatorias vinculadas a esta. Como la estadística es una función sobre las muestras aleatorias (muestras posibles) las evaluaciones que se realizan para cada una de las muestras posibles (estimaciones) conforman lo que vamos a denominar una distribución muestral.

Por ejemplo si planteamos al estimador del parámetro del total, recordar:

$$\theta=t_y=\sum_U y_i$$ 
Un estimador para este parámetro será:

$$\hat{\theta}=\hat{t}_y=\frac{N}{n} \sum_s y_i$$

Este $\hat{\theta}$ es una estadística sobre las muestras aleatorias, por lo tanto podemos decir que existe una distribución de probabilidad para este estimador, a esa distribución de probabilidad se conoce como distribución muestral.

Ejemplo práctico.

Supongamos que de una población de 6 personas tenemos la información de sus ingresos mensuales. $Y_{Ingresos}=\{2000,3000,3500,0,6000,4500\}$.
$N=6$

Supongamos que seleccionamos una muestra de tamaño $n=3$ de esta población, para ambos mecanismos de selección (s/rep, c/rep), se pide
para ambos mecanismos:

  - Conocer la cantidad de muestras posibles y mostrar estas.
  - Para el estimador

$$\hat{\bar{Y}}=\frac{1}{n}\sum_s y_i$$

construir su distribución muestral y calcular su esperanza y su varianza 

Para el estimador;

$$\hat{t}_y=\frac{N}{n}\sum_s y_i$$

construir su distribución muestral y calcular su esperanza y su varianza

Respuesta,

(S/rep) Las muestras posibles son 20, estas muestras posibles son:

```{r}
Y<-c(2000,3000,3500,0,6000,4500)
s<-combn(Y,3)
s
```

Para el estimador de la media;

Tomar en cuenta que el valor del parámetro de la media poblacional es:

$\mu_y=\sum_U y_i /N=3166.667$

```{r}
y<-apply(s,2,sum)/3 #Distribución muestral para el estimador de la media
hist(y)
abline(v=mean(Y),col="red",lwd=3)
# calcular la esperanza y la varianza
uy<-sum(y*(1/20)) # esperanza del estimador de la media
sum((y-uy)^2*(1/20)) # varianza de la media muestral
```

$$E[\hat{\theta}]=\sum_{Rs} \hat{\theta_s} P(\hat{\theta}=\hat{\theta_s})$$

$$V(\hat{\theta})=E[(\hat{\theta}-E[\hat{\theta}])^2]=\sum_{s}(\hat{\theta_s}-E[\hat{\theta}])^2*P(\hat{\theta}=\hat{\theta})$$

Nota, Si $E[\hat{\theta}]=\theta$ decimos que el estimador $\hat{\theta}$ es un estimador insesgado (sin **sesgo**)

El estimador de la media muestral, es un estimador insesgado de la media poblacional.

Para el estimador del total;

Tomar en cuenta que el valor del parámetro del total poblacional es: $t_y=\sum_U y_i=19000$

```{r}
ty<-apply(s,2,sum)*(6/3) #Distribución muestral para el estimador del total
hist(ty)
abline(v=sum(Y),col="red",lwd=3)
pty<-sum(ty*(1/20)) # esperanza
sum((ty-pty)^2*(1/20)) # varianza de la media muestral
```

$$E[\hat{t}_y]=E[N*\bar{Y}]=N E[\bar{Y}]=N*u_y=N*\frac{\sum_U y_i}{N}=\sum_U {y_i}=t_y$$
Repetir los cálculos para un muestreo con reposición. Muestras probables
$6^3=N^n=216$.

```{r,eval=FALSE}
Y<-round(rnorm(25,30,5))
s<-combn(Y,10)
y<-apply(s,2,sum)/10
hist(y)
abline(v=mean(Y),col="red",lwd=2)
```

## Propiedades de los estimadores

Se busca que un estimador cumpla al menos 2 de las siguientes propiedades:

### Estimador insesgado

$$E[\hat{\theta}]=\theta$$

### Estimador eficiente

$$V[\hat{\theta}_1]<V[\hat{\theta}_2]$$

Se dice que $\hat{\theta}_1$ es más eficiente que $\hat{\theta}_2$ si tiene una menor varianza

## Distribución muestral para la media

Recordar que para una población ($U$) con alguna variable $X$ de tipo cuantitativa se puede obtener el parámetro de la media, definido como:

$$\mu_x=\frac{\sum_U x_i}{N}$$

Esta variable $X$ en la población por lo tanto tiene su media $\mu_x$ y
también tiene su varianza, denotada por

$$V(X)=\sigma_x^2=\frac{\sum_U (x_i-\mu_x)^2}{N}$$

> Teorema:

Sean $X_1,X_2,\ldots,X_n$ variables aleatorias para una muestra de
tamaño $n$ extraida de la población $U$, donde estas $X_i$
independientes e idénticamente distribuidas (iid) como:
$X_i\sim .(E[X_i]=\mu_x,V(X_i)=\sigma_x^2)$, entonces, si:

$$\bar{X}=\frac{\sum_s x_i}{n}$$

Tenemos que

$$E[\bar{X}]=\mu_x$$

$$V(\bar{X})=\sigma^2_{\bar{x}}=\frac{\sigma^2_x}{n}$$

Demostración,

$$E[\bar{X}]=E\left[\frac{\sum_s x_i}{n}\right]=\frac{1}{n}E[x_1+x_2+\ldots+x_n]=\frac{1}{n}\left(E[x_1]+E[x_2]+\ldots+E[x_n] \right)=$$
$$=\frac{1}{n}(\mu_x+\mu_x+\ldots+\mu_x)=\frac{n \mu_x}{n}=\mu_x$$

Si, $X$ e $Y$ son independientes $Cov(X,Y)=0$.

$$V(X+Y)=V(X)+V(Y)$$

$$V(\bar{X})=V\left(\frac{\sum_s x_i}{n}\right)=\frac{1}{n^2}V(x_1+x_2+\ldots+x_n)=\frac{1}{n^2}\{V(x_1)+\ldots+V(x_n)\}=$$
$$=\frac{1}{n^2}(\sigma^2_x+\sigma^2_x+\ldots+\sigma^2_x)=\frac{n \sigma_x^2}{n^2}=\frac{\sigma^2_x}{n}$$
Nota: Cuando no es posible tener acceso al valor de $\sigma^2_x$ se
puede estimar este parámetro, mediante la muestra usando en su lugar a
la varianza muestral:

$$\hat{S}^2_x=\frac{\sum_s (x_i-\bar{x})^2}{n-1}$$

## Teorema del límite central

> Teorema:

Si $\bar{X}$ es la media de una muestra aleatoria de tamaño $n$. Tomada
de una población $U$ con media $\mu_x$ y varianza finita $\sigma^2_x$.
Entonces la forma límite de la distribución de:

$$Z=\frac{\bar{X}-E[\bar{X}]}{\sqrt{V(\bar{X})}}=\frac{\bar{X}-\mu_x}{\frac{\sigma_x}{\sqrt{n}}}$$
a medida que $n \rightarrow \infty$, podemos asegurar que
$Z\sim N(0,1)$, en este marco se puede decir a medida que $n$ es más
grande:

$$\bar{X}\sim N\left(\mu_x,\frac{\sigma^2_x}{n}\right)$$

Nota: esta idea de $n$ grande se usa tradicionalmente el valor de
$n>30$, hay textos que plantean $n=20$.

Simulación del teorema del límite central:

```{r}
N<-1000000
x<-round(runif(N,18,60),0)
hist(x)
n<-100
choose(N,n)

#simular 10000 muestras distintas de tamaño n y calcular su media.
xbar<-NULL
for(i in 1:10000){
  s<-sample(x,n)
  xbar[i]<-mean(s)
  print(i)
}
hist(xbar)
plot(density(xbar),col="blue",lwd=2)
points(density(rnorm(10^6,mean(x),sqrt(var(x)*((n-1)/n))/sqrt(n))),type="l",col="red",lwd=2)
```

## Distribución muestral para la diferencia de medias

Sean dos poblaciones $U_1$ y $U_2$ independientes con medias y varianzas
respectivamente: $\mu_{x_1}$ y $\mu_{x_2}$, $\sigma^2_{x_1}$ y
$\sigma^2_{x_2}$.

> Teorema:

La distribución muestral de las diferencias de media
$\bar{X_1}-\bar{X_2}$ esta tiene una distribución aproximadamente normal
($n\rightarrow \infty$) con medias y varianzas dadas por:

$$E[\bar{X_1}-\bar{X_2}]=\mu_{x_1}-\mu_{x_2}$$

$$V(\bar{X_1}-\bar{X_2})=\frac{\sigma^2_{x_1}}{n_1}+\frac{\sigma^2_{x_2}}{n_2}$$
Demostración:

$$E[\bar{X_1}-\bar{X_2}]=E[\bar{X_1}]-E[\bar{X_2}]=\mu_{x_1}-\mu_{x_2}$$

$$V(\bar{X_1}-\bar{X_2})=V(\bar{X_1})+V(\bar{X_2})=\frac{\sigma^2_{x_1}}{n_1}+\frac{\sigma^2_{x_2}}{n_2}$$

Por el teorema del limite central con $n\geq30$:

$$\bar{X_1}-\bar{X_2}\sim N\left(\mu_{x_1}-\mu_{x_2},\frac{\sigma^2_{x_1}}{n_1}+\frac{\sigma^2_{x_2}}{n_2}\right)$$

## Distribución muestral para la proporción

La proporción no es nada más que un caso especial de la media para $X$
que toma valores binarios según alguna característica de interés.

Sea $P_A=\frac{\#A}{N}=\frac{\sum_U x_i}{N}$, $x_i=1$ si $i \in A$
$x_i=0$ eoc. la proporción de alguna característica de la población.

Así la el estimador de la proporción sera:

$$\hat{P}_A=\frac{\sum_s{x_i}}{n}=\frac{\#a}{n}$$

> Teorema:

Para el estadístico $\hat{P}_A$ se cumple cuando $n$ tiende a infinito
los siguientes resultados:

-   $E[\hat{P}_A]=P_A$
-   $V(\hat{P}_A)=\frac{\sigma^2_A}{n}$
-   $\hat{P}_A\sim N(P_A,\frac{\sigma^2_A}{n})$, cuando
    $n \rightarrow \infty$

Donde $\sigma^2_A$, sabiendo que $x_i$ es binaria.

$$\sigma^2_A=\frac{\sum_U(x_i-\mu_x)^2}{N}= P_A *(1-P_A)$$ Demostración

$$\mu_x=\frac{\sum_U{x_i}}{N}=\frac{\#A}{N}=P_A$$
$$\sigma^2_A=\frac{\sum_U(x_i-P_A)^2}{N}=\frac{\sum_U x_i^2-2P_A \sum_U{x_i}+NP_A^2}{N}=$$
$$=\frac{NP_A-2P_A NP_A+NP_A^2}{N}=P_A-P_A^2=P_A(1-P_A)$$

```{r}
N<-100000
x<-round(runif(N,18,60))
a<-(x>30)*1
mean(a)#P_A
n<-100
r<-10000
pa<-NULL
for(i in 1:r){
s<-sample(a,n)
pa[i]<-mean(s)
}
PA<-mean(a)
plot(density(pa),col="blue",lwd=1.5)
points(density(rnorm(10^6,PA,sqrt(PA*(1-PA)/n))),col="red",type="l",lwd=2)
```

Ejercicio:

De una población de 150 estudiantes de la materia de estadística I se
toma una muestra de 40 estudiantes, sobre los cuales se realiza un test
sobre 100 puntos. Con los siguientes resultados:

59 54 61 58 66 56 35 42 49 65 61 61 58 57 57 60 55 63 66 48 52 54 49 54
55 32 60 40 53 67 54 60 44 74 55 24 43 56 62 50

Calcule:

-   la probabilidad que el promedio de nota sea menor a 50,
-   la probabilidad que el promedio de nota sea mayor a 60
-   la probabilidad que el promedio de nota se encuentre entre 50 y 55

Solución,

Como información $N=150$, $n=40$,

$$\bar{X}=54.225$$

$$\hat{S}^2_x=99.35833$$ Usando el teorema del limite central, podemos
decir (aproximar) que:

$$\bar{X}\sim N\left(\mu_x\approx\bar{x},\frac{\sigma^2_x}{n}\approx \frac{\hat{S}^2_x}{n} \right)=N(54.225,2.484)$$

La probabilidad que el promedio de nota sea menor a 50,

$$P(\bar{X}<50)=P\left(\frac{\bar{X}-\mu_x}{\frac{\sigma_x}{\sqrt{n}}} <\frac{50-54.225}{\sqrt{2.484}}\right)=P(Z<-2.68)=\phi(-2.68)=$$
$$=0.00368$$

-   la probabilidad que el promedio de nota sea mayor a 60

$$P(\bar{X}>60)=P(Z>3.66)=1-P(Z\leq 3.66)=1-\phi(3.66)=0.00013$$

-   la probabilidad que el promedio de nota se encuentre entre 50 y 55

## Distribución muestral para la varianza

Recordar que para una población $U$, si observamos a una variable de
interés respecto sus características podemos obtener medidas de
centralidad y también medidas de variabilidad, por ejemplo, sea $X$ una
variables definida para toda la población, y definamos los siguientes
parámetros de $X$.

$$\mu_x=\frac{\sum_U x_i}{N}$$

Esta $\mu_x$ es una medida de centralidad, normalmente conocida como
media, promedio de $X$, la otra medida puede ser:

$$\sigma^2_x=\frac{\sum_U (x_i-\mu_x)^2}{N}$$

$\sigma^2_x$ es la varianza poblacional

Ejemplo,

Sea una población de $N=5$ elementos con la variable
$X=\{10,15,20,20,35\}$, calcular $\mu_x$ y $\sigma^2_x$.

-   $\mu_x=20$
-   $\sigma^2_x=70$

Suponer que se toman muestras aleatorias de esta población de tamaño
$n=3$ sin reposición. La cantidad de muestras posibles es 10.

```{r}
x<-c(10,15,20,20,35)
s<-combn(x,3)
s
#distribución muestral de la media
mean(apply(s, 2, mean)) 
```

Pensemos para el caso de la varianza en posibles estadísticos
(estimadores):

$$\hat{\theta}_1=\hat{\sigma}^2_x=\frac{\sum_s (x_i-\bar{x})^2}{n}$$

$$\hat{\theta}_2=\hat{S}^2_x=\frac{\sum_s (x_i-\bar{x})^2}{n-1}$$

```{r}
x<-c(10,15,20,20,35)
n<-3;N<-5
s
var(x)*((N-1)/N)

theta1<-apply(s,2,var)*((n-1)/n)
theta2<-apply(s,2,var)


mean(theta1)-70
mean(theta2)-70

plot(density(theta1),xlim=c(-50,300))
points(density(theta2),col="red",type="l")



```

Notar que para el ejemplo $E[\hat{\theta_1}]$ ni $E[\hat{\theta_2}]$ se
acercan a $\sigma^2_x$, sin embargo, $E[\hat{\theta}_2]=S^2_x$.

$$S^2_x=\frac{\sum_U (x_i-\mu_x)^2}{N-1}$$ Viendo los resultados en una
simulación

```{r}
N<-1000
set.seed(1527)
x<-round(rnorm(N,60,10),0)
mean(x)#mu
sum((x-mean(x))^2)/N#sigma
n<-60
theta1<-NULL
theta2<-NULL
r<-20000
for(i in 1:r){
  aux<-sample(x,n)
  theta1[i]<-var(aux)*((n-1)/n)
  theta2[i]<-var(aux)
}
plot(density(theta1),col="red")
points(density(theta2),col="blue",type="l")
abline(v=var(x)*((N-1)/N))
abline(v=mean(theta1),col="red")
abline(v=mean(theta2),col="blue")

var(x)*((N-1)/N)#parámetro
mean(theta1)#estimador por copia /n
mean(theta2)#varianza muestral /n-1
```

> Teorema

Sea $X_1,X_2,\ldots,X_n$ una muestra aleatoria extraída de una población
Normal $N(\mu_x,\sigma^2_x)$, definamos al estadístico:

$$\hat{S}^2_x=\frac{\sum_s (x_i-\bar{x})^2}{n-1}$$

Entonces, se cumple

$$\chi^2=\frac{(n-1)\hat{S}^2_x}{\sigma^2_x}=\frac{\sum_s (x_i-\bar{x})^2}{\sigma^2_x}\sim \chi^2(n-1)$$

Simulación;

```{r}
sigma2x<-var(x)*((N-1)/N)#parámetro
chi2<-(theta2*(n-1))/sigma2x

plot(density(chi2))
curve(dchisq(x,df=59),add=T,col="red")
```

## Distribución $\chi^2$

Se dice que una variable aleatoria $X$ tiene una distribución
Chi-cuadrado $\chi^2$ con $v$ grados de libertad. Se escribe como:
$X \sim \chi^2(v)$, donde el $Rx=\{x>0\}$, si su función de densidad es:

$$f(x)=\frac{1}{2^\frac{v}{2} \Gamma(\frac{v}{2})}*x^{\frac{v}{2}-1}*e^{-\frac{x}{2}}$$

```{r}
curve(dchisq(x,1),xlim=c(0,60),ylim=c(0,0.4))
for(v in 2:50){
curve(dchisq(x,v),add=T,col=v)
}
curve(dchisq(x,10),xlim=c(0,60))
abline(v=10)

```

Donde,

$$E[X]=v$$ $$V(X)=2v$$

Ejercicio 1,

Para una muestra aleatoria de $n=30$, se busca estimar la varianza
poblacional, mediante la varianza muestral, suponiendo que la variable
de interés

$$X\sim N(\mu_x,\sigma_x^2=16)$$

Encuentre la probabilidad que la varianza muestral se encuentre entre 12
y 18.

Solución,

$$P(12<\hat{S}^2_x<18)=P\left(\frac{29*12}{16}<\frac{(n-1)\hat{S}^2_x}{\sigma^2_x}<\frac{29*18}{16}\right)=$$

$$=P(21.75<\chi^2<32.635)=F(32.635)_{\chi^2_{29}}-F(21.75)_{\chi^2_{29}}=0.5377$$

```{r}
pchisq(32.635,29)-pchisq(21.75,29)
```

Ejercicio 2,

Encuentre la probabilidad de que una muestra aleatoria de $n=25$ de un
población normal con varianza $\sigma_x^2=9$, tenga una varianza
muestral $\hat{S^2}$ entre 4 y 15.

$$P(4<\hat{S}^2_x<15)=P(4*24/9<\frac{(n-1)\hat{S}^2_x}{\sigma^2_x}<15*24/9)=P(10.66<\chi^2 <40)$$
$$P(10.66<\chi^2 <40)=F(40)-F(10.66)=0.9786-0.0087=0.9699$$

```{r}
pchisq(40,24)#F(40) para un chi2(v=24)
pchisq(10.66,24)#F(10.66) para un chi2(v=24)
curve(dchisq(x,24),xlim=c(0,60))
abline(v=c(10.66,40),col="red")
```

Tomar en cuenta que:

$$\chi^2=\frac{(n-1)\hat{S}^2_x}{\sigma^2_x}=\frac{\sum_s (x_i-\bar{x})^2}{\sigma^2_x}\sim \chi^2(n-1)$$

```{r}
#ejemplo para usar R para calcular probabilidades de la Chi2
pchisq(4,10) # F(t)=P(X<t): F(4)
```

Nota,

$$\frac{\sum_s (x_i-\bar{x})^2}{\sigma^2_x}=\sum_s\left(\frac{x_i-\bar{x}}{\sigma_x}\right)^2$$
En el fondo la distribución $\chi^2$ es la suma de variables aleatorias
Normales estándar al cuadrado.

## Distribución t-student

> Teorema

Sea $Z$ una variable aleatoria normal estándar y $V$ una variable
aleatoria chi-cuadrado con $v$ grados de libertad. Si $Z$ y $V$ son
independientes, entonces la distribución de la variable aleatoria $X$,
donde:

$$X=\frac{Z}{\sqrt{V/v}}$$ Se comporta como una distribución $t$ con $v$
grados de libertad. En notación, decimos $X\sim t(v)$.

$$f(x)=\frac{\Gamma(\frac{v+1}{2})}{\Gamma{(\frac{v}{2})}\sqrt{v\pi} }\left(1+\frac{x^2}{v} \right)^{-(\frac{v+1}{2})}, \quad -\infty<x<\infty$$

Al igual que la distribución normal estándar, la $t$ es simétrica al
rededor del cero. Y levemente más plana que una normal.

Nota: Cuando $v\rightarrow \infty$ la
$t \sim N(\mu=0,\sigma^2=\frac{v}{v-2})$

```{r}
v<-5
curve(dnorm(x,0,sqrt(v/(v-2))),xlim=c(-5,5),ylim=c(0,0.4),main="5 grados de libertad")
curve(dt(x,v),xlim=c(-5,5),main="t-student (v=10)",col="red",add=T)

v<-50
curve(dnorm(x,0,sqrt(v/(v-2))),xlim=c(-5,5),ylim=c(0,0.4),main="50 grados de libertad")
curve(dt(x,v),xlim=c(-5,5),main="t-student (v=10)",col="red",add=T)
```

> Corolario

Sean $X_1, X_2, \ldots, X_n$ variables aleatorias e independientes e
idénticamente distribuidas (iid)
$X_i\sim N(\mu,\sigma^2_x), \quad i=\{1,\ldots,n\}$. Sean los
estimadores:

$$\bar{X}=\frac{\sum_s x_i}{n} \quad y \quad \hat{S}^2_x=\frac{\sum_s (x_i-\bar{X})^2}{n-1}$$

Entonces,

$$
\frac{\bar{X}-\mu}{\hat{S}/\sqrt{n}}\sim t(v=n-1)
$$

Apariencia de la $t$

```{r}
curve(dt(x,2),xlim=c(-5,5),ylim=c(0,0.4))
for(v in 3:30){
  curve(dt(x,v),xlim=c(-5,5),col=v,add=T)
}
```

En R, para obtener $P(X<t)=F(t)$ con $X\sim t(v)$.

```{r}
# P(X<2)=F(2), X ~ t(v=10)
pt(2,10)
```

Ejercicio 1, Sea $X\sim t(v=14)$. Calcular:

-   $P(X>0.67)=1-P(X\leq 0.67)=1-F(0.67)=1-0.7431=0.2569$
-   $P(X<0.5)=F(0.5)=0.6875$
-   $P(-1.96<X<1.96)=F(1,96)-F(-1.96)=0.9649-0.0351=0.9298$

Ejercicio 2, Sea $X\sim t(v=20)$

-   $P(X>0.5)=1-P(X\leq0.5)=1-F(0.5)=0.3113$
-   $P(X>0)=1-P(X\leq 0)=F(0)=0.5$
-   $P(X<1)=F(1)=0.8354$
-   $P(-1<X<1)=F(1)-F(-1)=0.6707$

## Distribución Fisher

> Teorema

Sean $U$ y $V$ dos variables aleatorias independientes, con
$U\sim \chi^2(v_1)$ y $V \sim \chi^2(v_2)$. Y sea la variable $X$
definida como:

$$X=\frac{U/v_1}{V/v_2}$$ Así, decimos que $X$ se distribuye como una
Fisher, $X\sim F(v_1,v_2)$, donde estas $v_1$ y $v_2$ son los grados de
libertad de la Fisher. La forma de la distribución $f(x)$ es:

$$
f(x)=\frac{\left(\frac{v_1}{v_2} \right)^{v_1/2} x^{v_1/2-1}\Gamma{(\frac{v_1+v_2}{2})} }{\Gamma{(\frac{v_1}{2})} \Gamma{(\frac{v_2}{2})}\left(1+\frac{v_1}{v_2}x \right)^{(v_1+v_2)/2}}, \quad x>0
$$

### Para las varianzas muestrales

Suponga que las muetsras aleatorias de tamaños $n_1$ y $n_2$ se
selecciona de 2 poblaciones normales con varianzas $\sigma^2_1$ y
$\sigma^2_2$ respectivamente. Sabemos:

$$\chi^2_1=\frac{(n_1-1)\hat{S}_1^2}{\sigma^2_1}\sim \chi^2(v_1=n_1-1)$$

$$\chi^2_2=\frac{(n_2-1)\hat{S}_2^2}{\sigma^2_2}\sim \chi^2(v_2=n_2-1)$$
\> Teorema:

Si $\hat{S_1}$ y $\hat{S_2}$ son los estimadores de la varianza de
muestras aleatorias independientes entre ellas de tamaño $n_1$ y $n_2$,
tomadas de poblaciones normales con varianzas $\sigma^2_1$ y
$\sigma^2_2$ entonces:

$$\frac{\hat{S_1}^2/\sigma^2_1}{\hat{S_2}^2/\sigma^2_2}=\frac{\hat{S}_1^2*\sigma^2_2}{\hat{S}_2^2*\sigma^2_1}\sim F(v_1=n_1-1,v_2=n_2-1)$$

```{r}
curve(df(x,10,10),xlim=c(0,6))
curve(df(x,15,10),xlim=c(0,6))
curve(df(x,100,100),xlim=c(0,6))
curve(df(x,1000,1000),xlim=c(0,6))
curve(df(x,30,30),xlim=c(0,6))
```

En R

```{r}
#P(X<t)=F(t), donde  X ~ F(v1,v2). F(10,10), P(X<1)=F(1)
pf(1,10,10)
pf(1,50,50)
pf(1,30,30)
pf(1,25,60)
pf(1,25,15)
```

## Ejercicios

1.  Suponga que una variable aleatoria se distribuye normalmente con
    media $\mu$ y varianza $\sigma^2$. Extraiga una muestra aleatoria de
    cinco observaciones. ¿Cuál es la función de densidad conjunta de la
    muestra?
    
Solución, $x\sim N(\mu,\sigma^2)$, $n=5$, $x_1,x_2,x_3,x_4,x_5$

Se busca:

$$f(x_1,x_2,x_3,x_4,x_5)=f(x_1)*f(x_2)*\ldots*f(x_5)$$

Notar que las muestras son independientes e identicamente distribuidas.

$$f(x_1,x_2,x_3,x_4,x_5)=\frac{1}{\sigma\sqrt{2\pi}}e^{-(\frac{x_1-\mu}{\sigma})^2}*\ldots*\frac{1}{\sigma\sqrt{2\pi}}e^{-(\frac{x_5-\mu}{\sigma})^2}$$

2.  Los transistores tienen una vida de servicios que se distribuye exponencialmente con parámetro $\lambda$. Se toma una muestra aleatoria de $n$ transistores. ¿Cuál es la función de densidad conjunta de la muestra?

Solución, como información $x\sim exp(\lambda)$, donde x: La vida de un transistor.

$$f(x_1, \ldots,x_n)=\prod_{i=1}^n f(x_i)=\prod_{i=1}^n \lambda e^{-\lambda x_i}=\lambda^n e^{-\lambda \sum_{i=1}^n x_i}$$

3.  Se tiene una población de 6 personas, de las cuales se toma una muestra aleatoria sin reposición de tamaño 3. Demostrar que el estimador de la media es insesgado. Los valores de la población para una variable X son {20,20,25,28,30,26}.

Solución, recordar que:

$$E[\bar{X}]=\mu$$
```{r}
x<-c(20,20,25,28,30,26)
N<-6
n<-3
choose(N,n)
s<-combn(x,3)
xbar<-apply(s,2,mean)
mean(x)#mu
sum(xbar*1/20)#E[xbar]
```

$$6C3= \frac{6!}{(6-3)!3!}=\frac{4*5*6}{6}=20$$

4.  Del ejercicio anterior demostrar que la varianza del estimador de la media para poblaciones finitas queda como:

$$V(\bar{X})=\left(1-\frac{n}{N}\right) \frac{S_x^2}{n}$$
```{r}
sum((1/20)*(xbar-mean(xbar))^2)#V(xbar)
s2<-sum(((x-mean(x))^2)/(N-1))
s2<-var(x)
(1-n/N)*(s2/n)#formula
```

$$V(X)=E[(X-E[X])^2]=\sum_{Rx} (x_i-E[x_i])^2*P(X=x_i)$$
$$S^2_x=\frac{\sum_U (x_i-\mu)^2}{N-1}$$


5.  La capacidad máxima de un ascensor es de 500 kilos. Si la
    distribución $X$ de los pesos de los usuarios es

$$X\sim N(\mu=70,\sigma^2=100)$$

-   Cuál es la probabilidad de que 8 pasajeros sobrepasen ese límite
-   Cuál es la probabilidad de que 7 pasajeros sobrepasen ese límite
-   Cuál es la probabilidad de que 6 pasajeros sobrepasen ese límite

Solución,

Sean $X_1, X_2, \ldots,X_p$ con $p$ la cantidad de pasajeros en el
ascensor, suponemos que estas $X_i$ son iid
$X_i\sim N(\mu=70,\sigma=10)$. Se pide:

$$P(Y=X_1+X_2+\ldots+X_p>500)$$ Notar que la suma de variables normales
es también normal. $Y\sim N(\mu_y=p*\mu_x,\sigma^2_y=p*\sigma^2_x )$

$$E[Y]=E[X_1+\ldots+X_p]=E[X_1]+\ldots+E[X_p]=\mu_x+\ldots+\mu_x=p*\mu_x$$
$$V(Y)=V(X_1+\ldots+X_p)=V(X_1)+\ldots+V(X_p)=\sigma^2_x+\ldots+\sigma^2_x=p*\sigma^2_x$$

-   Cuál es la probabilidad de que 8 pasajeros sobrepasen ese límite;
    $Y\sim N(\mu_y=8*70=560,\sigma^2_y=8*100=800)$

$$P(Y>500)=P(Z>\frac{500-560}{\sqrt{800}})=P(Z>-2.12)=1-P(Z\leq -2.12)=1-\phi(-2.12)=$$

$$=1-0.017=0.983$$

-   Cuál es la probabilidad de que 7 pasajeros sobrepasen ese límite,
    $Y\sim N(\mu_y=490,\sigma^2_y=700)$

$$P(Y>500)=P(Z>0.3779)=1-\phi(0.3779)=1-0.647=0.353$$

-   Cuál es la probabilidad de que 6 pasajeros sobrepasen ese límite.
    (Ejercicio)

2.  El viaje en un autobús especial para ir de un campus de una
    universidad al campus de otra en una ciudad toma, en promedio, 28
    minutos, con una desviación estándar de 5 minutos. En cierta semana
    un autobús hizo el viaje 40 veces. ¿Cuál es la probabilidad de que
    el tiempo promedio del viaje sea mayor a 30 minutos?

Solución, $n=40$, Sea $X$ una va. que explica el tiempo de viaje entre
los dos campus. $X \sim .(\mu_x=28,\sigma=5)$, nos pide:

$$P(\bar{X}>30)$$

Recordar por el teorema del límite central que
$\bar{X} \sim N(\mu_{\bar{x}}=28,\sigma^2_{\bar{x}}= \sigma^2_x/n=25/40)$
cuando $n>30$.

$$P(\bar{X}>30)=P\left(\frac{\bar{X}-\mu_x}{\sigma_x/\sqrt{n}} >\frac{30-28}{5/\sqrt{40}}\right)=P(Z>2.52)=1-P(Z\leq 2.52)\approx 1-\phi(2.52)=$$

$$=1-0.9941=0.0059$$

3.  La calificación promedio de los estudiantes de primer año en un
    examen de aptitudes en cierta universidad es 540, con una desviación
    estándar de 50. Suponga que las medias se miden con cualquier grado
    de precisión. ¿Cuál es la probabilidad de que dos grupos
    seleccionados al azar, que constan de 32 y 50 estudiantes,
    respectivamente, difieran en sus calificaciones promedio por:

-   más de 20 puntos?

-   una cantidad entre 5 y 10 puntos? \_ Solución, como información se
    tienen 2 muestras, $n_1=32$, $n_2=50$. Sea
    $X\sim . (\mu=540,\sigma=50)$, nos piden analizar la diferencia de
    las medias de los dos grupos, $\bar{X_1}$, $\bar{X}_2$:

-   más de 20 puntos?

$$P( |\bar{X_1}-\bar{X}_2| >20)=1-P( |\bar{X_1}-\bar{X}_2| \leq 20)=1-P( -20\leq \bar{X_1}-\bar{X}_2 \leq 20)$$

Para la diferencia de medias
$\bar{X_1}-\bar{X}_2\sim N(\mu_{\bar{X_1}-\bar{X}_2}=\mu_x-\mu_x=0,\sigma^2_{\bar{X_1}-\bar{X}_2}=\frac{\sigma^2_1}{n_1}+\frac{\sigma^2_2}{n_2}=50^2/32+50^2/50)$,
entonces, $Y=\bar{X_1}-\bar{X}_2\sim N(\mu_y=0,\sigma^2_y=128.125)$,
bajo el supuesto que las $\bar{X}_1$ y $\bar{X}_2$ tienden a ser
normales por el teorema del límite central.

$$P( -20\leq \bar{X_1}-\bar{X}_2 \leq 20)=P(-20/11.31\leq Z \leq 20/11.31)\approx \phi(1.77)-\phi(-1.77)=$$

$$=0.962-0.038=0.9232$$
$$P( |\bar{X_1}-\bar{X}_2| >20)=1-0.9232=0.0768$$

-   una cantidad entre 5 y 10 puntos? (ejercicio)

4.  Suponga que las varianzas muestrales son mediciones continuas.
    Calcule la probabilidad de que una muestra aleatoria de 25
    observaciones, de una población normal con varianza $\sigma^2 = 6$,
    tenga una varianza muestral $\hat{S}^2$

-   mayor que 9.1
-   entre 3.462 y 10.745.

$$P(\hat{S}^2>9.1)=P\left(\frac{(n-1)\hat{S^2}}{\sigma^2_x}> 24*9.1/6 \right)=P(\chi^2>36.4)=1-P(\chi^2\leq36.4)=$$

$$=1-0.9498=0.0502$$

Teniendo en cuenta que $\chi^2\sim \chi^2(v=24)$

5.  Un fabricante de cierta marca de barras de cereal con bajo contenido
    de grasa afirma que el contenido promedio de grasa saturada en éstas
    es de 0.5 gramos. En una muestra aleatoria de 8 barras de cereal de
    esta marca se encontró que su contenido de grasa saturada era de
    0.6, 0.7, 0.7, 0.3, 0.4, 0.5, 0.4 y 0.2. ¿Estaría de acuerdo con tal
    afirmación? Suponga una distribución normal. ($t$)

